{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BDZR-hows48Z",
        "We_xzajk-9xY",
        "bgA1wp1y-yxZ",
        "ecz59xDYFx7c"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/Bias_GAN/blob/master/code/temperature_run_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ],
      "metadata": {
        "id": "h3yHWmlizCSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UtBBY2Vx4kVx",
        "outputId": "dd33516d-3b26-409d-e309-f36847182e13"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ngpu_info = !nvidia-smi\\ngpu_info = '\\n'.join(gpu_info)\\nif gpu_info.find('failed') >= 0:\\n  print('Not connected to a GPU')\\nelse:\\n  print(gpu_info)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "pM43-ErszEe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7baf94f1-6ee0-4cb7-bf58-8dc4ef8be7d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aim56009/Bias_GAN.git"
      ],
      "metadata": {
        "id": "UabaOuiKzJtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0911c6d-7397-4493-dc8d-07c4c0daaffb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bias_GAN'...\n",
            "remote: Enumerating objects: 842, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
            "remote: Total 842 (delta 54), reused 0 (delta 0), pack-reused 731\u001b[K\n",
            "Receiving objects: 100% (842/842), 130.21 MiB | 16.76 MiB/s, done.\n",
            "Resolving deltas: 100% (531/531), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pytorch_lightning\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "!pip install basemap\n",
        "!pip install importlib-metadata==4.0.1\n",
        "!pip install xarray==0.18.1\n",
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "yg_fJ3Fi0rzt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import torch\n",
        "import json\n",
        "import glob\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import argparse\n",
        "import pathlib\n",
        "import cv2\n",
        "import matplotlib\n",
        "\n",
        "\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "#from Bias_GAN.code.src.model import CycleGAN, Generator, DataModule                     \n",
        "from Bias_GAN.code.src.model import CycleGAN, Generator#, DataModule                     \n",
        "\n",
        "#from Bias_GAN.code.src.data import TestData, CycleDataset\n",
        "from Bias_GAN.code.src.utils import get_version, set_environment, get_checkpoint_path, save_config, log_transform, inv_norm_transform, inv_log_transform, inv_norm_minus1_to_plus1_transform, norm_minus1_to_plus1_transform \n",
        "from Bias_GAN.code.src.plots import PlotAnalysis, plot_basemap\n",
        "from Bias_GAN.code.src.callbacks import get_cycle_gan_callbacks, MAE_Callback\n",
        "from Bias_GAN.code.src.inference_tas import Inference, EvaluateCheckpoints, create_folder"
      ],
      "metadata": {
        "id": "ctpYd5RO0GJ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data.py"
      ],
      "metadata": {
        "id": "h3sTfmwpSezN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 config,\n",
        "                 training_batch_size: int = 4,\n",
        "                 test_batch_size: int = 64):\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.training_batch_size = training_batch_size\n",
        "        self.test_batch_size = test_batch_size\n",
        "\n",
        "    def setup(self, stage: str = None):\n",
        "\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.train = CycleDataset('train', self.config)\n",
        "            self.valid = CycleDataset('valid', self.config)\n",
        "\n",
        "        if stage == 'test':\n",
        "            self.test = CycleDataset('test', self.config)\n",
        "            self.valid = CycleDataset('valid', self.config)\n",
        "\n",
        "        if stage == 'predict':\n",
        "            self.test = ProjectionDataset(self.config)\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train,\n",
        "                         batch_size=self.training_batch_size,\n",
        "                         shuffle=True,\n",
        "                         num_workers=0,\n",
        "                         pin_memory=True)\n",
        "\n",
        "\n",
        "    def val_dataloader  (self):\n",
        "        return DataLoader(self.valid,\n",
        "                          batch_size=self.test_batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0,\n",
        "                          pin_memory=True)\n",
        "\n",
        "\n",
        "    def test_dataloader (self):\n",
        "        return DataLoader(self.test,\n",
        "                          batch_size=self.test_batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0,\n",
        "                          pin_memory=True)\n",
        "\n",
        "\n",
        "def show_image(image):\n",
        "    plt.imshow((image.squeeze()))\n",
        "\n",
        "\n",
        "def get_random_sample(dataset):\n",
        "    return dataset[np.random.randint(0, len(dataset))]\n"
      ],
      "metadata": {
        "id": "TogZq-xfjmC5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import cftime\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TestData():\n",
        "    \n",
        "    era5: xr.DataArray\n",
        "    gan: xr.DataArray\n",
        "    climate_model: xr.DataArray = None\n",
        "    cmip_model: xr.DataArray = None\n",
        "    gan_constrained: xr.DataArray = None\n",
        "    poem: xr.DataArray = None\n",
        "    quantile_mapping: xr.DataArray = None\n",
        "    uuid: str = None\n",
        "    model = None\n",
        "\n",
        "\n",
        "    def model_name_definition(self, key):\n",
        "        dict = {\n",
        "            'era5': 'ERA5',\n",
        "            'gan': 'GAN (unconstrained)',\n",
        "            'climate_model': 'Climate model',\n",
        "            'cmip_model': 'GFDL-ESM4',\n",
        "            'poem': 'CM2Mc-LPJmL',\n",
        "            'gan_constrained': 'GAN',\n",
        "            'quantile_mapping': 'Quantile mapping',\n",
        "        }\n",
        "        return dict[key]\n",
        "\n",
        "\n",
        "    def colors(self, key):\n",
        "        dict = {\n",
        "            'era5': 'k',\n",
        "            'gan': 'brown',\n",
        "            'cmip_model': 'b',\n",
        "            'climate_model': 'r',\n",
        "            'gan_constrained': 'c',\n",
        "            'quantile_mapping': 'm',\n",
        "        }\n",
        "        return dict[key]\n",
        "\n",
        "        \n",
        "    def convert_units(self):\n",
        "        \"\"\" from mm/s to mm/d\"\"\"\n",
        "        self.climate_model = self.climate_model#*3600*24\n",
        "        self.era5 = self.era5#*3600*24\n",
        "        self.gan = self.gan#*3600*24\n",
        "\n",
        "    \n",
        "    def crop_test_period(self):\n",
        "        print('')\n",
        "        print(f'Test set period: {self.gan.time[0].values} - {self.gan.time[-1].values}')\n",
        "        self.climate_model = self.climate_model.sel(time=slice(self.gan.time[0], self.gan.time[-1]))\n",
        "        self.era5 = self.era5.sel(time=slice(self.gan.time[0], self.gan.time[-1]))\n",
        "\n",
        "        \n",
        "    def show_mean(self):\n",
        "        print('')\n",
        "        print(f'Mean [mm/d]:')\n",
        "        print(f'ERA5: {self.era5.mean().values:2.3f}')\n",
        "        print(f'Climate Model: {self.climate_model.mean().values:2.3f}')\n",
        "        print(f'GAN:  {self.gan.mean().values:2.3f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CycleDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, stage, config, epsilon=0.0001):\n",
        "        \"\"\" \n",
        "            stage: train, valid, test\n",
        "        \"\"\"\n",
        "        self.transforms = config.transforms\n",
        "        self.epsilon = epsilon\n",
        "        self.config = config\n",
        "\n",
        "        if config.lazy:\n",
        "            self.cache = False\n",
        "            self.chunks = {'time': 1}\n",
        "        else:\n",
        "            self.cache = True\n",
        "            self.chunks = None\n",
        "\n",
        "        self.splits = {\n",
        "                \"train\": [str(config.train_start), str(config.train_end)],\n",
        "                \"valid\": [str(config.valid_start), str(config.valid_end)],\n",
        "                \"test\":  [str(config.test_start), str(config.test_end)],\n",
        "        }\n",
        "\n",
        "        self.stage = stage\n",
        "        self.climate_model = self.load_climate_model_data()\n",
        "        climate_model_reference = self.load_climate_model_data(is_reference=True)\n",
        "        self.era5 = self.load_era5_data()\n",
        "        era5_reference = self.load_era5_data(is_reference=True)\n",
        "        self.num_samples = len(self.era5.time.values)\n",
        "        self.era5 = self.apply_transforms(self.era5, era5_reference)\n",
        "        self.climate_model = self.apply_transforms(self.climate_model, climate_model_reference)\n",
        "\n",
        "\n",
        "    def load_climate_model_data(self, is_reference=False):\n",
        "        \"\"\" Y-domain samples \"\"\"\n",
        "\n",
        "        climate_model = xr.open_dataset(self.config.poem_path,\n",
        "                                        cache=self.cache, chunks=self.chunks)\n",
        "\n",
        "        \n",
        "        climate_model =  climate_model.tas\n",
        "\n",
        "        if not self.config.lazy:\n",
        "            climate_model = climate_model.load()\n",
        "\n",
        "        if is_reference:\n",
        "            climate_model = climate_model.sel(time=slice(self.splits['train'][0],\n",
        "                                                         self.splits['train'][1]))\n",
        "        else:\n",
        "            climate_model = climate_model.sel(time=slice(self.splits[self.stage][0],\n",
        "                                                         self.splits[self.stage][1]))\n",
        "\n",
        "        return climate_model\n",
        "\n",
        "\n",
        "    def load_era5_data(self, is_reference=False):\n",
        "        \"\"\" X-domain samples \"\"\"\n",
        "\n",
        "        era5 = xr.open_dataset(self.config.era5_path,\n",
        "                               cache=self.cache, chunks=self.chunks)\\\n",
        "                               .tas\n",
        "\n",
        "        if not self.config.lazy:\n",
        "            era5 = era5.load()\n",
        "\n",
        "        if is_reference:\n",
        "            era5 = era5.sel(time=slice(self.splits['train'][0],\n",
        "                                       self.splits['train'][1]))\n",
        "        else:\n",
        "            era5 = era5.sel(time=slice(self.splits[self.stage][0],\n",
        "                                 self.splits[self.stage][1]))\n",
        "\n",
        "        return era5\n",
        "        \n",
        "\n",
        "    def apply_transforms(self, data, data_ref):\n",
        "\n",
        "        if 'log' in self.transforms:\n",
        "            data = log_transform(data, self.epsilon)\n",
        "            data_ref = log_transform(data_ref, self.epsilon)\n",
        "\n",
        "        if 'normalize' in self.transforms:\n",
        "            data = norm_transform(data, data_ref)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in self.transforms:\n",
        "            data = norm_minus1_to_plus1_transform(data, data_ref)\n",
        "        \n",
        "        return data\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        x = torch.from_numpy(self.era5.isel(time=index).values).float().unsqueeze(0)\n",
        "        y = torch.from_numpy(self.climate_model.isel(time=index).values).float().unsqueeze(0)\n",
        "\n",
        "        sample = {'A': x, 'B': y}\n",
        "        \n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n"
      ],
      "metadata": {
        "id": "mIzh0Kl2Sg9U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main training loop"
      ],
      "metadata": {
        "id": "BDZR-hows48Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define MAE callback"
      ],
      "metadata": {
        "id": "AtINdQOafvRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MAE_Callback(Callback):\n",
        "    def __init__(self,logger,checkpoint_path,config, validation=True, lat_mean=False, plt_hist=False):\n",
        "        self.MAE_list = []\n",
        "        self.logger = logger\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.config = config\n",
        "        self.version = get_version(config.date,config.time)\n",
        "        self.validation = validation\n",
        "        self.lat_mean = lat_mean\n",
        "        self.plt_hist = plt_hist\n",
        "        \n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        checkpoint_files = glob.glob(str(self.checkpoint_path) + '/*.ckpt')\n",
        "        if not checkpoint_files:\n",
        "            test_data_ = None\n",
        "        else:\n",
        "            last_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
        "            data = EvaluateCheckpoints(checkpoint_path=last_checkpoint, config_path=self.config.config_path + self.version + \"/config_model.json\", save_model=True,validation=self.validation, version=self.version)\n",
        "            _, reconstruction_data = data.run()\n",
        "            test_data_ = data.get_test_data()\n",
        "\n",
        "\n",
        "        if test_data_ is None or not test_data_:\n",
        "            print(\"No test data available.\")\n",
        "            return\n",
        "\n",
        "        gan_data = getattr(test_data_, 'gan')\n",
        "        era5_data = getattr(test_data_, \"era5\")\n",
        "        \n",
        "        bias = gan_data.mean('time') - era5_data.mean('time') \n",
        "        print(\"GAN-OBS\",f\" \\t \\t MAE: {abs(bias).values.mean():2.3f} [mm/d]\")\n",
        "        self.MAE_list.append(abs(bias).values.mean())\n",
        "        print(\"MAE_list:\",self.MAE_list)\n",
        "\n",
        "        self.log('MAE', abs(bias).values.mean())\n",
        "\n",
        "        if test_data_ is not None and self.lat_mean==True:\n",
        "            data_era5 = era5_data.mean(dim=(\"lon\", \"time\"))\n",
        "            data_gan= gan_data.mean(dim=(\"lon\", \"time\"))\n",
        "            plt.figure()\n",
        "            plt.plot(data_gan.lat, data_gan.data,\n",
        "                      label=\"gan\",\n",
        "                      alpha=0.9,\n",
        "                      linestyle='-',\n",
        "                      linewidth=2,\n",
        "                      color=\"red\")\n",
        "            \n",
        "            plt.plot(data_era5.lat, data_era5,\n",
        "                      label=\"era5\",\n",
        "                      alpha=1,\n",
        "                      linestyle='--',\n",
        "                      linewidth=2,\n",
        "                      color=\"black\")\n",
        "            \n",
        "            plt.ylim(0,3)\n",
        "            plt.xlim(25,58)\n",
        "            plt.xlabel('Latitude')\n",
        "            plt.ylabel('Mean temperature [??]')\n",
        "            plt.grid()\n",
        "            plt.legend(loc='upper right')  \n",
        "            #plt.show()\n",
        "          \n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            im = Image.open(buf)\n",
        "            img = torchvision.transforms.ToTensor()(im)\n",
        "            \n",
        "            self.logger.experiment.add_image(f\"latitudinal_mean\", img, trainer.current_epoch)\n",
        "\n",
        "        if test_data_ is not None and self.plt_hist==True:\n",
        "            data_gan = getattr(test_data_, \"gan\").values.flatten()\n",
        "            data_era5 = getattr(test_data_, \"era5\").values.flatten()\n",
        "            plt.figure()\n",
        "            _ = plt.hist(data_gan,\n",
        "                        bins=100,\n",
        "                        histtype='step',\n",
        "                        log=True,\n",
        "                        label=\"gan\",\n",
        "                        alpha=0.9,\n",
        "                        density=True,\n",
        "                        linewidth=2,\n",
        "                        color=\"red\")\n",
        "            \n",
        "            _ = plt.hist(data_era5,\n",
        "                        bins=100,\n",
        "                        histtype='step',\n",
        "                        log=True,\n",
        "                        label=\"era5\",\n",
        "                        alpha=1,\n",
        "                        density=True,\n",
        "                        linewidth=2,\n",
        "                        color=\"black\")\n",
        "\n",
        "            plt.xlabel('Temperature [??]')\n",
        "            plt.ylabel('Histogram')\n",
        "            plt.xlim(0,400)\n",
        "            plt.grid()\n",
        "            plt.legend(loc='upper right')\n",
        "\n",
        "            #plt.show()\n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            im_ = Image.open(buf)\n",
        "            img_ = torchvision.transforms.ToTensor()(im_)\n",
        "            \n",
        "            self.logger.experiment.add_image(f\"histogram\", img_, trainer.current_epoch)"
      ],
      "metadata": {
        "id": "KpchPItBC6E6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Cycle GAN"
      ],
      "metadata": {
        "id": "RO0_lUBIfzaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cycle_gan(config, pretrain_path=False,validation=True,track_lat_mean=False,plt_hist=False ):\n",
        "    \"\"\" Main routing to train the Cycle GAN \"\"\"\n",
        "\n",
        "    config = Config()\n",
        "    global version\n",
        "    version = get_version(config.date,config.time)\n",
        "    print(f'Running model: {version}')\n",
        "    checkpoint_path = get_checkpoint_path(config, version)\n",
        "    set_environment()\n",
        "\n",
        "    tb_logger = TensorBoardLogger(config.tensorboard_path,name=\"\",version=version,default_hp_metric=False)\n",
        "    \n",
        "    create_folder(f\"/content/gdrive/MyDrive/bias_gan/results/{version}\")\n",
        "    save_config(config, version)\n",
        "    \n",
        "    mse_callback = MAE_Callback(tb_logger,checkpoint_path,config,validation,lat_mean=track_lat_mean,plt_hist=plt_hist)\n",
        "    \n",
        "    \n",
        "    trainer = pl.Trainer(callbacks=[mse_callback] + get_cycle_gan_callbacks(checkpoint_path),\n",
        "                         gpus = 1,\n",
        "                         max_epochs = config.epochs,\n",
        "                         precision = 16, \n",
        "                         num_sanity_val_steps = 1,\n",
        "                         logger = tb_logger,\n",
        "                         log_every_n_steps = config.log_every_n_steps,\n",
        "                         deterministic = False,\n",
        "                         accelerator=accelerator,\n",
        "                         enable_model_summary=False) \n",
        "    \n",
        "\n",
        "    datamodule = DataModule(config, training_batch_size = config.train_batch_size, test_batch_size = config.test_batch_size)\n",
        "    datamodule.setup(\"fit\")\n",
        "    \n",
        "    \n",
        "    if pretrain_path==False:\n",
        "      print(\"no pretraining\")\n",
        "      model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
        "                       epoch_decay = config.epochs // 2,running_bias=config.running_bias,num_resnet_blocks=config.num_resnet_layer, default_nbr_resnet=config.default_nbr_resnet)\n",
        "    else:\n",
        "      print(\"using pretrained model with path:\",pretrain_path)\n",
        "      model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
        "                       epoch_decay = config.epochs // 2, running_bias=config.running_bias,num_resnet_blocks=config.num_resnet_layer, default_nbr_resnet=config.default_nbr_resnet).load_from_checkpoint(pretrain_path)\n",
        "\n",
        "    trainer.fit(model, datamodule)\n",
        "\n",
        "    print('Training finished')\n",
        "    return model"
      ],
      "metadata": {
        "id": "efWHPrX2Ck9K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "Bq-nYOq2tAfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_pretrained_world_gan=False"
      ],
      "metadata": {
        "id": "fzdyv2Wdw1JG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RDSas-G6yYG1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\" \n",
        "    Training configuration parameters. For model evaluation parameters see\n",
        "    src/configuration.py.\n",
        "    \"\"\"\n",
        "    \n",
        "    scratch_path: str = '/content/gdrive/MyDrive/bias_gan/results'\n",
        "    tensorboard_path: str = f'{scratch_path}/'\n",
        "    checkpoint_path: str = f'{scratch_path}/'\n",
        "    config_path: str = f'{scratch_path}/'\n",
        "    poem_path: str = f\"/content/gdrive/MyDrive/bias_gan/data/detrend_pr_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
        "    era5_path: str = f\"/content/gdrive/MyDrive/bias_gan/data/detrend_pr_W5E5v2.0_regionbox_era5_1979-2014.nc\"\n",
        "   \n",
        "\n",
        "    results_path: str = f'{scratch_path}/'\n",
        "    projection_path: str = None\n",
        "\n",
        "    train_start: int = 1979\n",
        "    train_end: int = 1980 #2000 \n",
        "    valid_start: int = 2001 #was 2001\n",
        "    valid_end: int = 2004\n",
        "    test_start: int = 2004\n",
        "    test_end: int = 2014\n",
        "    \n",
        "    model_name: str = 'tibet_gan'\n",
        "\n",
        "    epochs: int = 2 # set to 250 for reproduction\n",
        "    progress_bar_refresh_rate: int = 50\n",
        "    train_batch_size: int = 1\n",
        "    test_batch_size: int = 64\n",
        "    transforms: List = field(default_factory=lambda: ['log', 'normalize_minus1_to_plus1'])\n",
        "    transformations = ['log', 'normalize_minus1_to_plus1']\n",
        "    rescale: bool = False\n",
        "    epsilon: float = 0.0001\n",
        "    lazy: bool = False\n",
        "    log_every_n_steps: int = 10 ### was 10\n",
        "    norm_output: bool = True\n",
        "    running_bias: bool = False\n",
        "\n",
        "    d_lr = 2e-4\n",
        "    g_lr = 2e-4\n",
        "    beta_1 = 0.5\n",
        "    beta_2 = 0.999\n",
        "    epoch_decay = 200\n",
        "    \n",
        "\n",
        "    time = datetime.now().time().strftime(\"%Hh_%Mm_%Ss\")\n",
        "    date = datetime.now().date().strftime(\"%Y_%m_%d\")\n",
        "\n",
        "    if load_pretrained_world_gan==True:\n",
        "      default_nbr_resnet=False\n",
        "      num_resnet_layer=7\n",
        "    else:\n",
        "      default_nbr_resnet=True\n",
        "      num_resnet_layer=6\n",
        "\n",
        "\n",
        "def main():\n",
        "    _ = train_cycle_gan(Config())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run"
      ],
      "metadata": {
        "id": "BuE3z8TfEMhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "do_training = True\n",
        "from_skratch = True\n",
        "\n",
        "track_lat_mean = True\n",
        "plt_hist=True\n",
        "\n",
        "runtime_instance = \"2023_02_10_10h_26m_48s\"\n",
        "\n",
        "if do_training == True:\n",
        "    accelerator=\"gpu\"\n",
        "\n",
        "    if from_skratch == True:\n",
        "        train_cycle_gan(Config(),validation=False,track_lat_mean=track_lat_mean,plt_hist=plt_hist)\n",
        "        \n",
        "\n",
        "    if from_skratch == False:\n",
        "        train_cycle_gan(Config(),f\"/content/gdrive/MyDrive/bias_gan/results/{runtime_instance}/last.ckpt\",validation=True,track_lat_mean=track_lat_mean,plt_hist=plt_hist)"
      ],
      "metadata": {
        "id": "Cid_5UwLyttz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "0d86a7b4-6c6a-4dbc-97fa-14adf90d7f48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model: 2023_02_15_10h_58m_44s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9ae0ad15672f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfrom_skratch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_cycle_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrack_lat_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_lat_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt_hist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f7e428e1e4f9>\u001b[0m in \u001b[0;36mtrain_cycle_gan\u001b[0;34m(config, pretrain_path, validation, track_lat_mean, plt_hist)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdatamodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdatamodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-78149196f6b0>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fit'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fb66664b6a6c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stage, config, epsilon)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclimate_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_climate_model_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mclimate_model_reference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_climate_model_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_reference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mera5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_era5_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fb66664b6a6c>\u001b[0m in \u001b[0;36mload_climate_model_data\u001b[0;34m(self, is_reference)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mclimate_model\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mclimate_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'tas'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "jHK2KTgauqDE",
        "outputId": "0cf5cfcc-f966-4397-8542-54dc3320a6bd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<xarray.Dataset>\n",
              "Dimensions:        (latitude: 60, longitude: 118, time: 13149)\n",
              "Coordinates:\n",
              "  * time           (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2014-12-31\n",
              "  * latitude       (latitude) float64 55.75 55.25 54.75 ... 27.25 26.75 26.25\n",
              "  * longitude      (longitude) float64 46.25 46.75 47.25 ... 103.8 104.2 104.8\n",
              "Data variables:\n",
              "    precipitation  (time, latitude, longitude) float32 ..."
            ],
            "text/html": [
              "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
              "<defs>\n",
              "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
              "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "</symbol>\n",
              "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
              "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "</symbol>\n",
              "</defs>\n",
              "</svg>\n",
              "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
              " *\n",
              " */\n",
              "\n",
              ":root {\n",
              "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
              "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
              "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
              "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
              "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
              "  --xr-background-color: var(--jp-layout-color0, white);\n",
              "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
              "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
              "}\n",
              "\n",
              "html[theme=dark],\n",
              "body.vscode-dark {\n",
              "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
              "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
              "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
              "  --xr-border-color: #1F1F1F;\n",
              "  --xr-disabled-color: #515151;\n",
              "  --xr-background-color: #111111;\n",
              "  --xr-background-color-row-even: #111111;\n",
              "  --xr-background-color-row-odd: #313131;\n",
              "}\n",
              "\n",
              ".xr-wrap {\n",
              "  display: block;\n",
              "  min-width: 300px;\n",
              "  max-width: 700px;\n",
              "}\n",
              "\n",
              ".xr-text-repr-fallback {\n",
              "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-header {\n",
              "  padding-top: 6px;\n",
              "  padding-bottom: 6px;\n",
              "  margin-bottom: 4px;\n",
              "  border-bottom: solid 1px var(--xr-border-color);\n",
              "}\n",
              "\n",
              ".xr-header > div,\n",
              ".xr-header > ul {\n",
              "  display: inline;\n",
              "  margin-top: 0;\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-obj-type,\n",
              ".xr-array-name {\n",
              "  margin-left: 2px;\n",
              "  margin-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-obj-type {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-sections {\n",
              "  padding-left: 0 !important;\n",
              "  display: grid;\n",
              "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
              "}\n",
              "\n",
              ".xr-section-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-section-item input {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-item input + label {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label {\n",
              "  cursor: pointer;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label:hover {\n",
              "  color: var(--xr-font-color0);\n",
              "}\n",
              "\n",
              ".xr-section-summary {\n",
              "  grid-column: 1;\n",
              "  color: var(--xr-font-color2);\n",
              "  font-weight: 500;\n",
              "}\n",
              "\n",
              ".xr-section-summary > span {\n",
              "  display: inline-block;\n",
              "  padding-left: 0.5em;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in + label:before {\n",
              "  display: inline-block;\n",
              "  content: '►';\n",
              "  font-size: 11px;\n",
              "  width: 15px;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label:before {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label:before {\n",
              "  content: '▼';\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label > span {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-summary,\n",
              ".xr-section-inline-details {\n",
              "  padding-top: 4px;\n",
              "  padding-bottom: 4px;\n",
              "}\n",
              "\n",
              ".xr-section-inline-details {\n",
              "  grid-column: 2 / -1;\n",
              "}\n",
              "\n",
              ".xr-section-details {\n",
              "  display: none;\n",
              "  grid-column: 1 / -1;\n",
              "  margin-bottom: 5px;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked ~ .xr-section-details {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-array-wrap {\n",
              "  grid-column: 1 / -1;\n",
              "  display: grid;\n",
              "  grid-template-columns: 20px auto;\n",
              "}\n",
              "\n",
              ".xr-array-wrap > label {\n",
              "  grid-column: 1;\n",
              "  vertical-align: top;\n",
              "}\n",
              "\n",
              ".xr-preview {\n",
              "  color: var(--xr-font-color3);\n",
              "}\n",
              "\n",
              ".xr-array-preview,\n",
              ".xr-array-data {\n",
              "  padding: 0 5px !important;\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-array-data,\n",
              ".xr-array-in:checked ~ .xr-array-preview {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-array-in:checked ~ .xr-array-data,\n",
              ".xr-array-preview {\n",
              "  display: inline-block;\n",
              "}\n",
              "\n",
              ".xr-dim-list {\n",
              "  display: inline-block !important;\n",
              "  list-style: none;\n",
              "  padding: 0 !important;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list li {\n",
              "  display: inline-block;\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list:before {\n",
              "  content: '(';\n",
              "}\n",
              "\n",
              ".xr-dim-list:after {\n",
              "  content: ')';\n",
              "}\n",
              "\n",
              ".xr-dim-list li:not(:last-child):after {\n",
              "  content: ',';\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-has-index {\n",
              "  font-weight: bold;\n",
              "}\n",
              "\n",
              ".xr-var-list,\n",
              ".xr-var-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-var-item > div,\n",
              ".xr-var-item label,\n",
              ".xr-var-item > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-even);\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-var-item > .xr-var-name:hover span {\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-var-list > li:nth-child(odd) > div,\n",
              ".xr-var-list > li:nth-child(odd) > label,\n",
              ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-odd);\n",
              "}\n",
              "\n",
              ".xr-var-name {\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-var-dims {\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-var-dtype {\n",
              "  grid-column: 3;\n",
              "  text-align: right;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-var-preview {\n",
              "  grid-column: 4;\n",
              "}\n",
              "\n",
              ".xr-var-name,\n",
              ".xr-var-dims,\n",
              ".xr-var-dtype,\n",
              ".xr-preview,\n",
              ".xr-attrs dt {\n",
              "  white-space: nowrap;\n",
              "  overflow: hidden;\n",
              "  text-overflow: ellipsis;\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-var-name:hover,\n",
              ".xr-var-dims:hover,\n",
              ".xr-var-dtype:hover,\n",
              ".xr-attrs dt:hover {\n",
              "  overflow: visible;\n",
              "  width: auto;\n",
              "  z-index: 1;\n",
              "}\n",
              "\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  display: none;\n",
              "  background-color: var(--xr-background-color) !important;\n",
              "  padding-bottom: 5px !important;\n",
              "}\n",
              "\n",
              ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
              ".xr-var-data-in:checked ~ .xr-var-data {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              ".xr-var-data > table {\n",
              "  float: right;\n",
              "}\n",
              "\n",
              ".xr-var-name span,\n",
              ".xr-var-data,\n",
              ".xr-attrs {\n",
              "  padding-left: 25px !important;\n",
              "}\n",
              "\n",
              ".xr-attrs,\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  grid-column: 1 / -1;\n",
              "}\n",
              "\n",
              "dl.xr-attrs {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  display: grid;\n",
              "  grid-template-columns: 125px auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt,\n",
              ".xr-attrs dd {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  float: left;\n",
              "  padding-right: 10px;\n",
              "  width: auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt {\n",
              "  font-weight: normal;\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-attrs dt:hover span {\n",
              "  display: inline-block;\n",
              "  background: var(--xr-background-color);\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-attrs dd {\n",
              "  grid-column: 2;\n",
              "  white-space: pre-wrap;\n",
              "  word-break: break-all;\n",
              "}\n",
              "\n",
              ".xr-icon-database,\n",
              ".xr-icon-file-text2 {\n",
              "  display: inline-block;\n",
              "  vertical-align: middle;\n",
              "  width: 1em;\n",
              "  height: 1.5em !important;\n",
              "  stroke-width: 0;\n",
              "  stroke: currentColor;\n",
              "  fill: currentColor;\n",
              "}\n",
              "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
              "Dimensions:        (latitude: 60, longitude: 118, time: 13149)\n",
              "Coordinates:\n",
              "  * time           (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2014-12-31\n",
              "  * latitude       (latitude) float64 55.75 55.25 54.75 ... 27.25 26.75 26.25\n",
              "  * longitude      (longitude) float64 46.25 46.75 47.25 ... 103.8 104.2 104.8\n",
              "Data variables:\n",
              "    precipitation  (time, latitude, longitude) float32 ...</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-8c4c16d1-ecbe-4318-b369-83a6bc8c3551' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-8c4c16d1-ecbe-4318-b369-83a6bc8c3551' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>latitude</span>: 60</li><li><span class='xr-has-index'>longitude</span>: 118</li><li><span class='xr-has-index'>time</span>: 13149</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-b6f0bba3-09d6-455b-87c0-a96d0f3f0456' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b6f0bba3-09d6-455b-87c0-a96d0f3f0456' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1979-01-01 ... 2014-12-31</div><input id='attrs-5e3962bd-5b4f-4f95-b180-60c00982b0c0' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-5e3962bd-5b4f-4f95-b180-60c00982b0c0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-270f8921-3f83-4c1c-9f28-315ee88134b4' class='xr-var-data-in' type='checkbox'><label for='data-270f8921-3f83-4c1c-9f28-315ee88134b4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1979-01-01T00:00:00.000000000&#x27;, &#x27;1979-01-02T00:00:00.000000000&#x27;,\n",
              "       &#x27;1979-01-03T00:00:00.000000000&#x27;, ..., &#x27;2014-12-29T00:00:00.000000000&#x27;,\n",
              "       &#x27;2014-12-30T00:00:00.000000000&#x27;, &#x27;2014-12-31T00:00:00.000000000&#x27;],\n",
              "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>55.75 55.25 54.75 ... 26.75 26.25</div><input id='attrs-43f71a25-abeb-49d3-85d4-6a39368633ab' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-43f71a25-abeb-49d3-85d4-6a39368633ab' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ada204be-dbeb-449e-b0e2-2b1f14b50e8d' class='xr-var-data-in' type='checkbox'><label for='data-ada204be-dbeb-449e-b0e2-2b1f14b50e8d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([55.75, 55.25, 54.75, 54.25, 53.75, 53.25, 52.75, 52.25, 51.75, 51.25,\n",
              "       50.75, 50.25, 49.75, 49.25, 48.75, 48.25, 47.75, 47.25, 46.75, 46.25,\n",
              "       45.75, 45.25, 44.75, 44.25, 43.75, 43.25, 42.75, 42.25, 41.75, 41.25,\n",
              "       40.75, 40.25, 39.75, 39.25, 38.75, 38.25, 37.75, 37.25, 36.75, 36.25,\n",
              "       35.75, 35.25, 34.75, 34.25, 33.75, 33.25, 32.75, 32.25, 31.75, 31.25,\n",
              "       30.75, 30.25, 29.75, 29.25, 28.75, 28.25, 27.75, 27.25, 26.75, 26.25])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>46.25 46.75 47.25 ... 104.2 104.8</div><input id='attrs-57ae47ad-8a57-4b94-b897-b3682103c62c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-57ae47ad-8a57-4b94-b897-b3682103c62c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7daa67c7-10d6-47b3-b0f7-71f3fdc5ffc1' class='xr-var-data-in' type='checkbox'><label for='data-7daa67c7-10d6-47b3-b0f7-71f3fdc5ffc1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([ 46.25,  46.75,  47.25,  47.75,  48.25,  48.75,  49.25,  49.75,  50.25,\n",
              "        50.75,  51.25,  51.75,  52.25,  52.75,  53.25,  53.75,  54.25,  54.75,\n",
              "        55.25,  55.75,  56.25,  56.75,  57.25,  57.75,  58.25,  58.75,  59.25,\n",
              "        59.75,  60.25,  60.75,  61.25,  61.75,  62.25,  62.75,  63.25,  63.75,\n",
              "        64.25,  64.75,  65.25,  65.75,  66.25,  66.75,  67.25,  67.75,  68.25,\n",
              "        68.75,  69.25,  69.75,  70.25,  70.75,  71.25,  71.75,  72.25,  72.75,\n",
              "        73.25,  73.75,  74.25,  74.75,  75.25,  75.75,  76.25,  76.75,  77.25,\n",
              "        77.75,  78.25,  78.75,  79.25,  79.75,  80.25,  80.75,  81.25,  81.75,\n",
              "        82.25,  82.75,  83.25,  83.75,  84.25,  84.75,  85.25,  85.75,  86.25,\n",
              "        86.75,  87.25,  87.75,  88.25,  88.75,  89.25,  89.75,  90.25,  90.75,\n",
              "        91.25,  91.75,  92.25,  92.75,  93.25,  93.75,  94.25,  94.75,  95.25,\n",
              "        95.75,  96.25,  96.75,  97.25,  97.75,  98.25,  98.75,  99.25,  99.75,\n",
              "       100.25, 100.75, 101.25, 101.75, 102.25, 102.75, 103.25, 103.75, 104.25,\n",
              "       104.75])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-abf39d19-8b02-4f84-b110-d6554c580920' class='xr-section-summary-in' type='checkbox'  checked><label for='section-abf39d19-8b02-4f84-b110-d6554c580920' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>precipitation</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-db6e5aad-1477-4fdb-8c11-425db93ab30f' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-db6e5aad-1477-4fdb-8c11-425db93ab30f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0f8ee80d-128b-4a94-b32f-ad7446e1be3e' class='xr-var-data-in' type='checkbox'><label for='data-0f8ee80d-128b-4a94-b32f-ad7446e1be3e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>precipitation_flux</dd><dt><span>long_name :</span></dt><dd>Precipitation</dd><dt><span>units :</span></dt><dd>kg m-2 s-1</dd></dl></div><div class='xr-var-data'><pre>[93094920 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-4e8245ff-e5b5-4a5c-8310-3a7c6eaf1d60' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-4e8245ff-e5b5-4a5c-8310-3a7c6eaf1d60' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model_ = xr.open_dataset(Config.poem_path)\n",
        "climate_model_.tas.values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "PbuFdUw4AcKQ",
        "outputId": "01153000-fc75-467a-9d85-2a757d1d743b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4ddd2ac2a8d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclimate_model_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoem_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclimate_model_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'tas'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model = xr.open_dataset(Config.era5_path)\n",
        "climate_model.tas.values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "MZig-jepR5s3",
        "outputId": "38c7c328-7408-4dc3-ec36-a062b627845b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-dc517234644e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclimate_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mera5_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclimate_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'tas'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorboard logging"
      ],
      "metadata": {
        "id": "au8YMzdenH1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "-C07ecZu8qKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if do_training==True: \n",
        "    %tensorboard --logdir /content/gdrive/MyDrive/bias_gan/results/{version}/"
      ],
      "metadata": {
        "id": "T6I1AxV4Y3Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if do_training==False: \n",
        "  %tensorboard --logdir /content/gdrive/MyDrive/bias_gan/results/{runtime_instance}/"
      ],
      "metadata": {
        "id": "7BBG_ha-qWOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save images from tensorboard files to drive"
      ],
      "metadata": {
        "id": "gAnl0A4nBRxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_images_for_gif = False\n",
        "\n",
        "\n",
        "def save_tensorboard_images(event_file, outdir):\n",
        "    event_acc = event_accumulator.EventAccumulator(event_file, size_guidance={'images': 0})\n",
        "    event_acc.Reload()\n",
        "\n",
        "    outdir = pathlib.Path(outdir)\n",
        "    outdir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    for tag in event_acc.Tags()['images']:\n",
        "        events = event_acc.Images(tag)\n",
        "\n",
        "        tag_name = tag.replace('/', '_')\n",
        "        dirpath = outdir / tag_name\n",
        "        dirpath.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "        for index, event in enumerate(events):\n",
        "            s = np.frombuffer(event.encoded_image_string, dtype=np.uint8)\n",
        "            image = cv2.imdecode(s, cv2.IMREAD_COLOR)\n",
        "            #outpath = dirpath / '{:04}.jpg'.format(index) \n",
        "            outpath = dirpath / '{:04}.jpg'.format(index+239)\n",
        "            cv2.imwrite(outpath.as_posix(), image)\n",
        "\n",
        "\n",
        "\n",
        "if save_images_for_gif == True:\n",
        "    path_to_event_file = '/content/gdrive/MyDrive/bias_gan/results/2023_02_02_10h_51m_31s/events.out.tfevents.1675331519.gpu-001.2945388.0'\n",
        "    outdir = \"/content/gdrive/MyDrive/bias_gan/results/2023_02_02_10h_51m_31s\"\n",
        "    save_tensorboard_images(path_to_event_file, outdir)"
      ],
      "metadata": {
        "id": "t5Q2Rfc63KGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/MyDrive/bias_gan/results/latitudinal_mean\""
      ],
      "metadata": {
        "id": "SBN8GgyGrbRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get MAE"
      ],
      "metadata": {
        "id": "oqGDAuCARcGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Config_adjusted_trafo = Config\n",
        "Config_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\n",
        "len_training_dataset = len(CycleDataset('train', Config_adjusted_trafo))\n",
        "len_valid_dataset = len(CycleDataset('valid', Config_adjusted_trafo))\n",
        "len_test_dataset = len(CycleDataset('test', Config_adjusted_trafo))\n",
        "\n",
        "len_training_dataset, len_valid_dataset, len_test_dataset"
      ],
      "metadata": {
        "id": "sB1qvReJWBZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_mae_training_fragments = False\n",
        "if combine_mae_training_fragments:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.python.summary.summary_iterator import summary_iterator\n",
        "    epochs_0 = []\n",
        "    mae_values_0 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_01_19_16h_26m_23s/events.out.tfevents.1674145623.c0c1f3e09513.1224.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_0.append(e.step/len_training_dataset)\n",
        "                mae_values_0.append(v.simple_value)\n",
        "\n",
        "    \"\"\"\n",
        "    plt.plot(epochs_0, mae_values_0)\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"MAE\")\n",
        "    plt.title(\"MAE VS EPOCHS validation\")\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "\n",
        "    epochs_1 = []\n",
        "    mae_values_1 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_01_31_10h_24m_37s/events.out.tfevents.1675157093.dgx-002.1451939.4'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_1.append(e.step/len_training_dataset)\n",
        "                mae_values_1.append(v.simple_value)\n",
        "\n",
        "    epochs_2 = []\n",
        "    mae_values_2 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_01_31_19h_24m_28s/events.out.tfevents.1675189486.dgx-002.1619062.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_2.append(e.step/len_training_dataset)\n",
        "                mae_values_2.append(v.simple_value)\n",
        "\n",
        "\n",
        "    epochs_3 = []\n",
        "    mae_values_3 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_02_01_16h_44m_03s/events.out.tfevents.1675266262.dgx-002.1953755.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_3.append(e.step/len_training_dataset)\n",
        "                mae_values_3.append(v.simple_value)            \n",
        "\n",
        "    epochs_4 = []\n",
        "    mae_values_4 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_02_02_08h_29m_00s/events.out.tfevents.1675322959.dgx-002.2208864.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_4.append(e.step/len_training_dataset)\n",
        "                mae_values_4.append(v.simple_value)\n",
        "\n",
        "    epochs_5 = []\n",
        "    mae_values_5 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_02_02_10h_51m_31s/events.out.tfevents.1675331519.gpu-001.2945388.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_5.append(e.step/len_training_dataset)\n",
        "                mae_values_5.append(v.simple_value)\n",
        "\n",
        "\n",
        "    epoch_total = epochs_0 + [69+i for i in epochs_1] + [69+34+i for i in epochs_2] +[69+34+65+i for i in epochs_3]+[69+34+65+59+i for i in epochs_4]+[69+34+65+59+7+i for i in epochs_5]\n",
        "    mae_total = mae_values_0 + mae_values_1 + mae_values_2 + mae_values_3 + mae_values_4 +mae_values_5\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(epoch_total, mae_total)\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"MAE\")\n",
        "    plt.title(\"MAE VS EPOCHS validation\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WdTyNs2GYYYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make gifs\n"
      ],
      "metadata": {
        "id": "jN5-KFkOAlKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def create_gif(images_folder, gif_name, duration=0.7):\n",
        "    images = []\n",
        "    filenames = sorted((images_folder).glob(\"*.jpg\"))\n",
        "    for filename in filenames:\n",
        "        images.append(imageio.imread(filename))\n",
        "    imageio.mimsave(gif_name, images, duration=duration)"
      ],
      "metadata": {
        "id": "lZHuZsiW_etN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_gif = False\n",
        "\n",
        "# create gif and save to the current directory\n",
        "gif_name = '/content/gdrive/MyDrive/bias_gan/results/histogram.gif'\n",
        "images_folder = pathlib.Path(\"/content/gdrive/MyDrive/bias_gan/results/histograms_combined\")\n",
        "\n",
        "if create_gif == True:\n",
        "    create_gif(images_folder, gif_name)\n",
        "    # show the gif in colab\n",
        "    from IPython.display import Image\n",
        "    with open(gif_name,'rb') as f:\n",
        "        display(Image(data=f.read()))"
      ],
      "metadata": {
        "id": "6xjbNbXbAjsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create gif and save to the current directory\n",
        "gif_name = '/content/gdrive/MyDrive/bias_gan/results/latitudinal_mean.gif'\n",
        "images_folder = pathlib.Path(\"/content/gdrive/MyDrive/bias_gan/results/latitudinal_mean\")\n",
        "\n",
        "if create_gif == True:\n",
        "    create_gif(images_folder, gif_name)\n",
        "    # show the gif in colab\n",
        "    from IPython.display import Image\n",
        "    with open(gif_name,'rb') as f:\n",
        "        display(Image(data=f.read()))"
      ],
      "metadata": {
        "id": "jPI5K0BB_73k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "2adJLjPo-15I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Evaluation\n"
      ],
      "metadata": {
        "id": "VGpAmsXwFzjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if do_training==False: \n",
        "  version_ = runtime_instance\n",
        "else:\n",
        "  version_ = version\n",
        "\n",
        "\n",
        "checkpoint_path = f\"/content/gdrive/MyDrive/bias_gan/results/{version_}/last.ckpt\" \n",
        "config_path = f\"/content/gdrive/MyDrive/bias_gan/results/{version_}/config_model.json\"\n",
        "\n",
        "data = EvaluateCheckpoints(checkpoint_path=checkpoint_path, config_path=config_path, save_model=True, version=version_)"
      ],
      "metadata": {
        "id": "LeBFJMy3-NSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data, reconstruct_data = data.run()\n",
        "test_data = data.get_test_data()"
      ],
      "metadata": {
        "id": "2VuJjIiTjpnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average absolute error\n",
        "avg_gan = np.round(np.sum(abs(test_data.era5.values - inv_transform(test_data.gan.values.squeeze())))/(4018*60*118),2)\n",
        "print(\"average absolute differnce in tas values obs-gan:\",avg_gan)\n",
        "\n",
        "#average absolute error\n",
        "avg_cm = np.round(np.sum(abs(test_data.era5.values - test_data.climate_model.values))/(4018*60*118),2)\n",
        "print(\"average absolute differnce in tas values obs-cm:\",avg_cm)"
      ],
      "metadata": {
        "id": "IWsZqEQSb7QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edata_era5 = test_data.era5.values.mean(axis=(0,2))\n",
        "\n",
        "#data_gan= inv_transform(test_data.gan.values.squeeze()).mean(axis=(0,2))\n",
        "data_gan = inv_transform(test_data.gan, climate_model_reference).squeeze().mean(axis=(0,2))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(test_data.gan.lat, data_gan,\n",
        "          label=\"gan\",\n",
        "          alpha=0.9,\n",
        "          linestyle='-',\n",
        "          linewidth=2,\n",
        "          color=\"red\")\n",
        "\n",
        "\n",
        "plt.plot(test_data.era5.lat, data_era5,\n",
        "          label=\"era5\",\n",
        "          alpha=1,\n",
        "          linestyle='--',\n",
        "          linewidth=2,\n",
        "          color=\"black\")\n",
        "plt.xlim(25,58)\n",
        "plt.xlabel('Latitude')\n",
        "plt.ylabel('Mean temperature [K]')\n",
        "plt.grid()\n",
        "plt.legend(loc='upper right')  \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N05Qp2BGvC3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_gan= inv_transform(test_data.gan.values.squeeze()).mean(axis=(0,2))\n",
        "data_gan = inv_transform(test_data.gan, climate_model_reference).squeeze().mean(axis=(0,2))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(test_data.gan.lat, data_gan,\n",
        "          label=\"gan\",\n",
        "          alpha=0.9,\n",
        "          linestyle='-',\n",
        "          linewidth=2,\n",
        "          color=\"red\")\n",
        "\n",
        "\n",
        "plt.xlim(25,58)\n",
        "plt.xlabel('Latitude')\n",
        "plt.ylabel('Mean temperature [K]')\n",
        "plt.grid()\n",
        "plt.legend(loc='upper right')  \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CAQf3HBSKZx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_climate_model_reference_data():\n",
        "\n",
        "        climate_model = xr.open_dataset(Config.poem_path)\n",
        "\n",
        "        if 'poem_precipitation' in climate_model.variables:\n",
        "            climate_model =  climate_model.poem_precipitation\n",
        "        else:\n",
        "            climate_model =  climate_model.precipitation\n",
        "\n",
        "        if not Config.lazy:\n",
        "            climate_model = climate_model.load()\n",
        "\n",
        "        climate_model = climate_model.sel(time=slice(str(Config.train_start), str(Config.train_end)))\n",
        "\n",
        "        return climate_model"
      ],
      "metadata": {
        "id": "41L73-wJGb6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_climate_model_data( is_reference=False):\n",
        "        \"\"\" Y-domain samples \"\"\"\n",
        "\n",
        "        stage = \"test\"\n",
        "        splits = {\n",
        "                \"train\": [str(Config.train_start), str(Config.train_end)],\n",
        "                \"valid\": [str(Config.valid_start), str(Config.valid_end)],\n",
        "                \"test\":  [str(Config.test_start), str(Config.test_end)],\n",
        "        }\n",
        "\n",
        "\n",
        "        climate_model = xr.open_dataset(Config.poem_path,\n",
        "                                        cache=True, chunks=None)\n",
        "\n",
        "        if 'poem_precipitation' in climate_model.variables:\n",
        "            climate_model =  climate_model.tas\n",
        "        else:\n",
        "            climate_model =  climate_model.tas\n",
        "\n",
        "        if not Config.lazy:\n",
        "            climate_model = climate_model.load()\n",
        "\n",
        "        if is_reference:\n",
        "            climate_model = climate_model.sel(time=slice(splits['train'][0],\n",
        "                                                         splits['train'][1]))\n",
        "        else:\n",
        "            climate_model = climate_model.sel(time=slice(splits[stage][0],\n",
        "                                                         splits[stage][1]))\n",
        "\n",
        "        return climate_model"
      ],
      "metadata": {
        "id": "J-q4qbwBHvqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Config.transforms"
      ],
      "metadata": {
        "id": "SwG7BD0NLJLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_transforms( data, data_ref):\n",
        "\n",
        "        if 'log' in Config.transforms:\n",
        "            data = log_transform(data, epsilon)\n",
        "            data_ref = log_transform(data_ref, epsilon)\n",
        "\n",
        "        if 'normalize' in Config.transforms:\n",
        "            data = norm_transform(data, data_ref)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in Config.transforms:\n",
        "            data = norm_minus1_to_plus1_transform(data, data_ref)\n",
        "        \n",
        "        return data"
      ],
      "metadata": {
        "id": "LUbUJ2PaGPxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon=0.0001\n",
        "\n",
        "climate_model = load_climate_model_data()\n",
        "climate_model_reference = load_climate_model_data(is_reference=True)\n",
        "\n",
        "#era5 = load_era5_data()\n",
        "#era5_reference = load_era5_data(is_reference=True)\n",
        "#era5 = apply_transforms(era5, era5_reference)\n",
        "\n",
        "climate_model_ = apply_transforms(climate_model, climate_model_reference)"
      ],
      "metadata": {
        "id": "wY2EbtdpHeta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model,inv_transform(climate_model_,climate_model_reference)"
      ],
      "metadata": {
        "id": "V9WMbmDaLvwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model.shape"
      ],
      "metadata": {
        "id": "Pl7ITwQbLEHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4018*60*118"
      ],
      "metadata": {
        "id": "H7NGmPW1LJdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(np.round(climate_model,0) == np.round(inv_transform(climate_model_,climate_model_reference),0))-28447440"
      ],
      "metadata": {
        "id": "Lh7veIHAK7fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create reconstructions"
      ],
      "metadata": {
        "id": "Dxf0UZB5Komf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Config_adjusted_trafo = Config\n",
        "Config_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\n",
        "dataset = CycleDataset('train', Config_adjusted_trafo)"
      ],
      "metadata": {
        "id": "g5OZ8gZ5Luyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " nbr_reconstruction_examples = 2"
      ],
      "metadata": {
        "id": "1ZkFP4HVuJ_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define inverse transformation and define forward/backward models"
      ],
      "metadata": {
        "id": "HwHZWZGZKz6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, generator_model: torch.nn.Module, constrain=True):\n",
        "        super(Generator, self).__init__()\n",
        "        self.generator =  generator_model\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.generator(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "bvm--uyQ9__7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inv_transform(data, reference=None):\n",
        "        \"\"\" The output equals ERA5, therefore it needs to be\n",
        "            constraind with respect to it\n",
        "        \"\"\"\n",
        "        if reference is None:\n",
        "            reference = xr.open_dataset(Config.era5_path).tas.sel(time=slice(str(Config.train_start), str(Config.train_end))).values\n",
        "\n",
        "        if 'log' in Config.transformations:\n",
        "            reference = log_transform(reference, Config.epsilon)\n",
        "\n",
        "        if 'normalize' in Config.transformations:\n",
        "            data = inv_norm_transform(data, reference)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in Config.transformations:\n",
        "            data = inv_norm_minus1_to_plus1_transform(data, reference)\n",
        "\n",
        "        if 'log' in Config.transformations:\n",
        "            data = inv_log_transform(data, Config.epsilon)\n",
        "\n",
        "        return data\n",
        "\n",
        "ckpt_path = Config.checkpoint_path + f\"{version_}\" +\"/last.ckpt\"\n",
        "\n",
        "model_fw = CycleGAN().load_from_checkpoint(checkpoint_path=ckpt_path)\n",
        "model_fw.freeze()\n",
        "model_fw = model_fw.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "model_fw = Generator(model_fw.g_B2A, constrain=False)\n",
        "\n",
        "\n",
        "model_bw = CycleGAN().load_from_checkpoint(checkpoint_path=ckpt_path)\n",
        "model_bw.freeze()\n",
        "model_bw = model_bw.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "model_bw = Generator(model_bw.g_A2B, constrain=False)"
      ],
      "metadata": {
        "id": "Uqoma3efKsr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reconstruction starting with climate model"
      ],
      "metadata": {
        "id": "Tyc4ELg9K5Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(nbr_reconstruction_examples):\n",
        "    test_data_ = dataset[i]  \n",
        "\n",
        "    obs = test_data_['B'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))   \n",
        "    gan = model_fw(obs)\n",
        "    rec = model_bw(gan)\n",
        "\n",
        "    #print(np.array(obs.cpu()))\n",
        "    #print( climate_model_reference)\n",
        "    #data_obs = inv_transform(np.array(obs.cpu()),climate_model_reference).squeeze()\n",
        "    data_obs = inv_transform(obs.squeeze().cpu())\n",
        "    data_gan = inv_transform(gan.squeeze().cpu())\n",
        "    data_rec = inv_transform(rec.squeeze().cpu())\n",
        "\n",
        "    print(\"average predicted error in temperature:\",np.round(torch.sum(abs(data_obs-data_gan).cpu())/(60*118),0),\"degrees K\")\n",
        "\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    cs = ax[0].pcolormesh(data_obs.squeeze().cpu())\n",
        "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
        "    sm = plt.cm.ScalarMappable(norm=norm)\n",
        "    sm.set_array([])\n",
        "\n",
        "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
        "    ax[0].set_title(\"climate model data\")\n",
        "\n",
        "    cs = ax[1].pcolormesh(data_gan.squeeze().cpu() )#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
        "    ax[1].set_title(\"generated observation (gan)\")\n",
        "\n",
        "    cs = ax[2].pcolormesh(data_rec.squeeze().cpu() ) #, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
        "    ax[2].set_title(\"reconstruction of climate model data\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eVaBt7A3K6Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reconstruction starting with observations"
      ],
      "metadata": {
        "id": "4NBbOL6iLC73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(nbr_reconstruction_examples):\n",
        "    test_data_ = dataset[i]  \n",
        "\n",
        "    model = test_data_['A'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))   \n",
        "    gan = model_fw(model)\n",
        "    rec = model_bw(gan)\n",
        "\n",
        "    data_model = inv_transform(model.squeeze().cpu())#*3600*24\n",
        "    data_gan = inv_transform(gan.squeeze().cpu())#*3600*24\n",
        "    data_rec = inv_transform(rec.squeeze().cpu())#*3600*24\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    cs = ax[0].pcolormesh(data_model.squeeze().cpu())#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
        "    ax[0].set_title(\"observation data\")\n",
        "\n",
        "    cs = ax[1].pcolormesh(data_gan.squeeze().cpu())#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
        "    ax[1].set_title(\"generated climate model data (gan)\")\n",
        "\n",
        "    cs = ax[2].pcolormesh(data_rec.squeeze().cpu())#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
        "    ax[2].set_title(\"reconstruction of observation data\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JJP2BpKVLIR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot  **frames**"
      ],
      "metadata": {
        "id": "rOMdYqIrEBEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot single frames"
      ],
      "metadata": {
        "id": "aAh6JIg0nCC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "set the chose_day parameter to plot the precipitation on a specific day"
      ],
      "metadata": {
        "id": "o7NrV7zfnELz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chose_day=10\n",
        "\n",
        "PlotAnalysis(test_data).single_frames(time_index=chose_day)\n",
        "PlotAnalysis(test_data).single_frames(projection=\"cyl\",time_index=chose_day)"
      ],
      "metadata": {
        "id": "UdNmJG-jHyGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot of the average test_data for each data"
      ],
      "metadata": {
        "id": "rInMTAV9t7jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PlotAnalysis(test_data).avg_frames(projection=\"cyl\",scale_precip_by = 10)"
      ],
      "metadata": {
        "id": "04wEV8jGnfkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot of the average **errors** between era5 & gan / climate_model"
      ],
      "metadata": {
        "id": "dZrUokXJuHxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PlotAnalysis(test_data).avg_frames_abs_err(projection=\"cyl\", scale_precip_by = 20)"
      ],
      "metadata": {
        "id": "xLvmxOQVgsqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**: plot spatial plot - mean Error - also show lands"
      ],
      "metadata": {
        "id": "M5e8_eN2Ggk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot **histogram** statistics\n",
        "Precipitation rates averaged over time and longitudes and relative frequency histograms"
      ],
      "metadata": {
        "id": "lXihevAlFamY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## histogram no log"
      ],
      "metadata": {
        "id": "O9B4JKnll_iR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we plot the histogram over the daily precipitation values in the test dataset. "
      ],
      "metadata": {
        "id": "EfvPYKo3QKg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(4, 4),  constrained_layout=True)\n",
        "\n",
        "PlotAnalysis(test_data).histograms(single_plot=False, ax=ax, show_legend=True, annotate=True,log=False,xlim_end=30)"
      ],
      "metadata": {
        "id": "gNlHXpskQVoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## histogram log on **density**"
      ],
      "metadata": {
        "id": "Et2xtAYKmCfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because it is hard to see anything because precipitations over 50 are very rare and thus the 3 plots are right above eachother, we apply the log to the probability desnity to better see the differences."
      ],
      "metadata": {
        "id": "QYgwpz8CQYYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "\n",
        "PlotAnalysis(test_data).histograms(single_plot=False, ax=ax, show_legend=True, annotate=True,log=True)"
      ],
      "metadata": {
        "id": "fmVwmg1G3-Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot histogram log density **differences**"
      ],
      "metadata": {
        "id": "b5VbVeqyF92W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "days in the test_data set"
      ],
      "metadata": {
        "id": "PyzvlWO2Lsaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(getattr(test_data,\"gan\").time)"
      ],
      "metadata": {
        "id": "VQ4w2of3LT6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "\n",
        "PlotAnalysis(test_data).histogram_diff(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ],
      "metadata": {
        "id": "m60e1vv6F-B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot log **precipitation**"
      ],
      "metadata": {
        "id": "nolk4FVNloC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying the **log** to the data itself instead of to the amount of points in the bins as in the plot before results in the density to be on one scale:"
      ],
      "metadata": {
        "id": "zUlODjL9PuRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "PlotAnalysis(test_data).log_histograms(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ],
      "metadata": {
        "id": "wX7CMfFUE-JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot histogram log precipitation differences"
      ],
      "metadata": {
        "id": "jbqJBrV8O3un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PlotAnalysis(test_data).log_histogram_diff(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ],
      "metadata": {
        "id": "qp7f8K0nO-a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot **latitudinal** **mean**"
      ],
      "metadata": {
        "id": "tJEOwVMmFkZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PlotAnalysis(test_data).latitudinal_mean()"
      ],
      "metadata": {
        "id": "DkWfYREj2shn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#try loading finished gan world"
      ],
      "metadata": {
        "id": "z4WBVpYz12aZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## new cyclegan model code"
      ],
      "metadata": {
        "id": "2VU5Nw1XryeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load new model: "
      ],
      "metadata": {
        "id": "yxdRevxDrseD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#state_dict = torch.load(\"/content/gdrive/MyDrive/bias_gan/results/pretrained_gan_world/last.ckpt\",map_location=torch.device('cpu'))\n",
        "#CycleGAN(num_resnet_layer = 7).load_state_dict(state_dict, strict=False)"
      ],
      "metadata": {
        "id": "0X9prBKKNM_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SSIM comparison"
      ],
      "metadata": {
        "id": "y8PqETITpXRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Open the .nc file\n",
        "data_gan = xr.open_dataset(f'/content/gdrive/MyDrive/bias_gan/results/{version_}/gan.nc').gan_precipitation\n",
        "data_era5 = xr.open_dataset(f\"/content/gdrive/MyDrive/bias_gan/data_gan/pr_W5E5v2.0_regionbox_era5_1979-2014.nc\").era5_precipitation #*3600*24 \n",
        "data_model = xr.open_dataset(f\"/content/gdrive/MyDrive/bias_gan/data_gan/pr_gfdl-esm4_historical_regionbox_1979-2014.nc\").precipitation #*3600*24 \n",
        "\n",
        "# Extract the data you want to calculate SSIM for\n",
        "gan_values = data_gan.values\n",
        "era5_values = data_era5.values\n",
        "model_values = data_model.values"
      ],
      "metadata": {
        "id": "YlKppGu7pY4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate the SSIM for the gan only for 4018 entries bc thats the size of the test dataset"
      ],
      "metadata": {
        "id": "4owxn8PdRjQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SSIM for the climate model"
      ],
      "metadata": {
        "id": "fS2t5DtwR1xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate SSIM\n",
        "model_score, model_diff = ssim(era5_values[-4018:,:,:], model_values[-4018:,:,:], full=True)\n",
        "print(\"model score:\", model_score)"
      ],
      "metadata": {
        "id": "TXUNamb4RzRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SSIM for the GAN"
      ],
      "metadata": {
        "id": "dSVlMhL0SFhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gan_score, gan_diff = ssim(era5_values[-4018:,:,:], gan_values, full=True)\n",
        "print(\"gan score:\", gan_score)"
      ],
      "metadata": {
        "id": "uTP5aLojNnkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan_values.shape,era5_values.shape,model_values.shape"
      ],
      "metadata": {
        "id": "jneyCa-iQ6HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare metrics"
      ],
      "metadata": {
        "id": "uzy2NsxwlnK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "instances = [\"2023_01_11_13h_04m_08s\",\"2023_01_12_05h_34m_48s\",\"2023_01_12_07h_34m_09s\",\"2023_01_13_07h_17m_53s\", \"2023_01_13_11h_06m_15s\",\"2023_01_14_08h_45m_11s\"]\n",
        "\n",
        "for i in instances: \n",
        "    evaluation_instance = i\n",
        "    checkpoint_path = f\"/content/gdrive/MyDrive/bias_gan/results/{evaluation_instance}/last.ckpt\" \n",
        "    config_path = f\"/content/gdrive/MyDrive/bias_gan/results/{evaluation_instance}/config_model.json\"\n",
        "    data = EvaluateCheckpoints(checkpoint_path=checkpoint_path, config_path=config_path, save_model=True)\n",
        "    data.run()\n",
        "    test_data = data.get_test_data()\n",
        "    print(\"\")\n",
        "    PlotAnalysis(test_data).avg_frames_abs_err(projection=\"cyl\", scale_precip_by = 10)\n",
        "    print(\"\")\n",
        "    PlotAnalysis(test_data).latitudinal_mean()\n",
        "    print(\"\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jX2K86s_lmdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data: raw output\n",
        "# check whats available in isimip\n",
        "\n",
        "\n",
        "# do we use the right data? the already bias corrected data (also with downscaling)\n",
        "\n",
        "# downscaled climate model"
      ],
      "metadata": {
        "id": "kcl90dmF9pKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. remove all trends and add again at the end !!!\n",
        "# 2. "
      ],
      "metadata": {
        "id": "pm0eVqjH92Es"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}