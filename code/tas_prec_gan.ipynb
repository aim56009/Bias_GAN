{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BDZR-hows48Z",
        "We_xzajk-9xY",
        "bgA1wp1y-yxZ",
        "ecz59xDYFx7c"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/Bias_GAN/blob/master/code/tas_prec_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ],
      "metadata": {
        "id": "h3yHWmlizCSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UtBBY2Vx4kVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "pM43-ErszEe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aim56009/Bias_GAN.git"
      ],
      "metadata": {
        "id": "UabaOuiKzJtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pytorch_lightning\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "!pip install basemap\n",
        "!pip install importlib-metadata==4.0.1\n",
        "!pip install xarray==0.18.1\n",
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "yg_fJ3Fi0rzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import torch\n",
        "import json\n",
        "import glob\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import argparse\n",
        "import pathlib\n",
        "import cv2\n",
        "import matplotlib\n",
        "\n",
        "\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "#from Bias_GAN.code.src.model import CycleGAN, Generator, DataModule                     \n",
        "from Bias_GAN.code.src.model import CycleGAN, Generator#, DataModule                     \n",
        "\n",
        "#from Bias_GAN.code.src.data import TestData, CycleDataset\n",
        "from Bias_GAN.code.src.utils import get_version, set_environment, get_checkpoint_path, save_config, log_transform, inv_norm_transform, inv_log_transform, inv_norm_minus1_to_plus1_transform, norm_minus1_to_plus1_transform \n",
        "from Bias_GAN.code.src.plots import PlotAnalysis, plot_basemap\n",
        "from Bias_GAN.code.src.callbacks import get_cycle_gan_callbacks, MAE_Callback\n",
        "from Bias_GAN.code.src.inference_tas import Inference, EvaluateCheckpoints, create_folder"
      ],
      "metadata": {
        "id": "ctpYd5RO0GJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data.py"
      ],
      "metadata": {
        "id": "h3sTfmwpSezN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 config,\n",
        "                 training_batch_size: int = 4,\n",
        "                 test_batch_size: int = 64):\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.training_batch_size = training_batch_size\n",
        "        self.test_batch_size = test_batch_size\n",
        "\n",
        "    def setup(self, stage: str = None):\n",
        "\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.train = CycleDataset('train', self.config)\n",
        "            self.valid = CycleDataset('valid', self.config)\n",
        "\n",
        "        if stage == 'test':\n",
        "            self.test = CycleDataset('test', self.config)\n",
        "            self.valid = CycleDataset('valid', self.config)\n",
        "\n",
        " \n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train,\n",
        "                         batch_size=self.training_batch_size,\n",
        "                         shuffle=True,\n",
        "                         num_workers=0,\n",
        "                         pin_memory=True)\n",
        "\n",
        "\n",
        "    def val_dataloader  (self):\n",
        "        return DataLoader(self.valid,\n",
        "                          batch_size=self.test_batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0,\n",
        "                          pin_memory=True)\n",
        "\n",
        "\n",
        "    def test_dataloader (self):\n",
        "        return DataLoader(self.test,\n",
        "                          batch_size=self.test_batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0,\n",
        "                          pin_memory=True)\n",
        "\n",
        "\n",
        "def show_image(image):\n",
        "    plt.imshow((image.squeeze()))\n",
        "\n",
        "\n",
        "def get_random_sample(dataset):\n",
        "    return dataset[np.random.randint(0, len(dataset))]\n"
      ],
      "metadata": {
        "id": "TogZq-xfjmC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import cftime\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TestData():\n",
        "    \n",
        "    era5: xr.DataArray\n",
        "    gan: xr.DataArray\n",
        "    climate_model: xr.DataArray = None\n",
        "    uuid: str = None\n",
        "    model = None\n",
        "\n",
        "\n",
        "    def model_name_definition(self, key):\n",
        "        dict = {\n",
        "            'era5': 'ERA5',\n",
        "            'gan': 'GAN (unconstrained)',\n",
        "            'climate_model': 'Climate model',\n",
        "        }\n",
        "        return dict[key]\n",
        "\n",
        "\n",
        "    def colors(self, key):\n",
        "        dict = {\n",
        "            'era5': 'k',\n",
        "            'gan': 'brown',\n",
        "            'climate_model': 'r',\n",
        "        }\n",
        "        return dict[key]\n",
        "\n",
        "        \n",
        "    def convert_units(self):\n",
        "        \"\"\" from mm/s to mm/d\"\"\"\n",
        "        self.climate_model = self.climate_model#*3600*24\n",
        "        self.era5 = self.era5#*3600*24\n",
        "        self.gan = self.gan#*3600*24\n",
        "\n",
        "    \n",
        "    def crop_test_period(self):\n",
        "        print('')\n",
        "        print(f'Test set period: {self.gan.time[0].values} - {self.gan.time[-1].values}')\n",
        "        self.climate_model = self.climate_model.sel(time=slice(self.gan.time[0], self.gan.time[-1]))\n",
        "        self.era5 = self.era5.sel(time=slice(self.gan.time[0], self.gan.time[-1]))\n",
        "\n",
        "        \n",
        "    def show_mean(self):\n",
        "        print('')\n",
        "        print(f'Mean [mm/d]:')\n",
        "        print(f'ERA5: {self.era5.mean().values:2.3f}')\n",
        "        print(f'Climate Model: {self.climate_model.mean().values:2.3f}')\n",
        "        print(f'GAN:  {self.gan.mean().values:2.3f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CycleDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, stage, config, epsilon=0.0001):\n",
        "        \"\"\" \n",
        "            stage: train, valid, test\n",
        "        \"\"\"\n",
        "        self.transforms = config.transforms\n",
        "        self.epsilon = epsilon\n",
        "        self.config = config\n",
        "\n",
        "        if config.lazy:\n",
        "            self.cache = False\n",
        "            self.chunks = {'time': 1}\n",
        "        else:\n",
        "            self.cache = True\n",
        "            self.chunks = None\n",
        "\n",
        "        self.splits = {\n",
        "                \"train\": [str(config.train_start), str(config.train_end)],\n",
        "                \"valid\": [str(config.valid_start), str(config.valid_end)],\n",
        "                \"test\":  [str(config.test_start), str(config.test_end)],\n",
        "        }\n",
        "\n",
        "        self.stage = stage\n",
        "\n",
        "        self.climate_model = self.load_climate_model_data()\n",
        "        climate_model_reference = self.load_climate_model_data(is_reference=True)\n",
        "\n",
        "        self.era5 = self.load_era5_data()\n",
        "        era5_reference = self.load_era5_data(is_reference=True)\n",
        "\n",
        "        self.num_samples = len(self.era5[0,:,0,0]) ###len(self.era5.time.values)\n",
        "\n",
        "        self.era5 = self.apply_transforms(self.era5, era5_reference)\n",
        "        self.climate_model = self.apply_transforms(self.climate_model, climate_model_reference)\n",
        "\n",
        "\n",
        "        print(\"self.era5\",self.era5)\n",
        "\n",
        "    def load_climate_model_data(self, is_reference=False):\n",
        "        \"\"\" Y-domain samples \"\"\"\n",
        "\n",
        "        climate_model_pr = xr.open_dataset(self.config.model_pr_path, cache=self.cache, chunks=self.chunks)\n",
        "        climate_model_pr =  climate_model_pr.precipitation\n",
        "        \n",
        "        climate_model_t = xr.open_dataset(self.config.model_t_path, cache=self.cache, chunks=self.chunks)\n",
        "        climate_model_t =  climate_model_t.tas\n",
        "        \n",
        "\n",
        "        if not self.config.lazy:\n",
        "            climate_model_pr = climate_model_pr.load()\n",
        "            climate_model_t = climate_model_t.load()\n",
        "\n",
        "        if is_reference:\n",
        "            climate_model_pr = climate_model_pr.sel(time=slice(self.splits['train'][0], self.splits['train'][1]))\n",
        "            climate_model_t = climate_model_t.sel(time=slice(self.splits['train'][0], self.splits['train'][1]))\n",
        "        else:\n",
        "            climate_model_pr = climate_model_pr.sel(time=slice(self.splits[self.stage][0],self.splits[self.stage][1]))\n",
        "            climate_model_t = climate_model_t.sel(time=slice(self.splits[self.stage][0],self.splits[self.stage][1]))\n",
        "\n",
        "        \n",
        "        climate_model = np.stack((climate_model_pr, climate_model_t),axis=0)\n",
        "\n",
        "        return climate_model\n",
        "\n",
        "\n",
        "    def load_era5_data(self, is_reference=False):\n",
        "        \"\"\" X-domain samples \"\"\"\n",
        "\n",
        "        era5_pr = xr.open_dataset(self.config.era5_pr_path,cache=self.cache, chunks=self.chunks).era5_precipitation\n",
        "        era5_t = xr.open_dataset(self.config.era5_t_path,cache=self.cache, chunks=self.chunks).tas\n",
        "\n",
        "        if not self.config.lazy:\n",
        "            era5_pr = era5_pr.load()\n",
        "            era5_t = era5_t.load()\n",
        "\n",
        "        if is_reference:\n",
        "            era5_pr = era5_pr.sel(time=slice(self.splits['train'][0],self.splits['train'][1]))\n",
        "            era5_t = era5_t.sel(time=slice(self.splits['train'][0],self.splits['train'][1]))\n",
        "\n",
        "        else:\n",
        "            era5_pr = era5_pr.sel(time=slice(self.splits[self.stage][0], self.splits[self.stage][1]))\n",
        "            era5_t = era5_t.sel(time=slice(self.splits[self.stage][0], self.splits[self.stage][1]))\n",
        "\n",
        "\n",
        "        #print(era5_pr)\n",
        "        #print(era5_t)\n",
        "        #print(\"shapes before adding era5:\",era5_pr.shape,era5_t.shape)\n",
        "        \n",
        "        #era5 = np.stack((era5_pr, era5_t),axis=0)\n",
        "\n",
        "        era5 = xr.concat([era5_pr, era5_t], dim=\"variable\")\n",
        "\n",
        "        #print(\"shapes after adding era5:\",era5.shape)\n",
        "        print(\"era5\",era5)\n",
        "\n",
        "        return era5\n",
        "        \n",
        "\n",
        "    def apply_transforms(self, data, data_ref):\n",
        "\n",
        "        if 'log' in self.transforms:\n",
        "            data = log_transform(data, self.epsilon)\n",
        "            data_ref = log_transform(data_ref, self.epsilon)\n",
        "\n",
        "        if 'normalize' in self.transforms:\n",
        "            data = norm_transform(data, data_ref)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in self.transforms:\n",
        "            data = norm_minus1_to_plus1_transform(data, data_ref)\n",
        "        \n",
        "        return data\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        \n",
        "        x = torch.from_numpy(self.era5.isel(time=index).values).float().unsqueeze(0)\n",
        "        y = torch.from_numpy(self.climate_model.isel(time=index).values).float().unsqueeze(0)\n",
        "\n",
        "        sample = {'A': x, 'B': y}\n",
        "        \n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n"
      ],
      "metadata": {
        "id": "mIzh0Kl2Sg9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_cycle_gan(Config(),validation=False,track_lat_mean=track_lat_mean,plt_hist=plt_hist)"
      ],
      "metadata": {
        "id": "HHb0dnst_Lpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main training loop"
      ],
      "metadata": {
        "id": "BDZR-hows48Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define MAE callback"
      ],
      "metadata": {
        "id": "AtINdQOafvRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MAE_Callback(Callback):\n",
        "    def __init__(self,logger,checkpoint_path,config, validation=True, lat_mean=False, plt_hist=False):\n",
        "        self.MAE_list = []\n",
        "        self.logger = logger\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.config = config\n",
        "        self.version = get_version(config.date,config.time)\n",
        "        self.validation = validation\n",
        "        self.lat_mean = lat_mean\n",
        "        self.plt_hist = plt_hist\n",
        "        \n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        checkpoint_files = glob.glob(str(self.checkpoint_path) + '/*.ckpt')\n",
        "        if not checkpoint_files:\n",
        "            test_data_ = None\n",
        "        else:\n",
        "            last_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
        "            data = EvaluateCheckpoints(checkpoint_path=last_checkpoint, config_path=self.config.config_path + self.version + \"/config_model.json\", save_model=True,validation=self.validation, version=self.version)\n",
        "            _, reconstruction_data = data.run()\n",
        "            test_data_ = data.get_test_data()\n",
        "\n",
        "\n",
        "        if test_data_ is None or not test_data_:\n",
        "            print(\"No test data available.\")\n",
        "            return\n",
        "\n",
        "        gan_data = getattr(test_data_, 'gan')\n",
        "        era5_data = getattr(test_data_, \"era5\")\n",
        "        \n",
        "        bias = gan_data.mean('time') - era5_data.mean('time') \n",
        "        print(\"GAN-OBS\",f\" \\t \\t MAE: {abs(bias).values.mean():2.3f} [mm/d]\")\n",
        "        self.MAE_list.append(abs(bias).values.mean())\n",
        "        print(\"MAE_list:\",self.MAE_list)\n",
        "\n",
        "        self.log('MAE', abs(bias).values.mean())\n",
        "\n",
        "        if test_data_ is not None and self.lat_mean==True:\n",
        "            data_era5 = era5_data.mean(dim=(\"lon\", \"time\"))\n",
        "            data_gan= gan_data.mean(dim=(\"lon\", \"time\"))\n",
        "            plt.figure()\n",
        "            plt.plot(data_gan.lat, data_gan.data,\n",
        "                      label=\"gan\",\n",
        "                      alpha=0.9,\n",
        "                      linestyle='-',\n",
        "                      linewidth=2,\n",
        "                      color=\"red\")\n",
        "            \n",
        "            plt.plot(data_era5.lat, data_era5,\n",
        "                      label=\"era5\",\n",
        "                      alpha=1,\n",
        "                      linestyle='--',\n",
        "                      linewidth=2,\n",
        "                      color=\"black\")\n",
        "            \n",
        "            plt.ylim(0,3)\n",
        "            plt.xlim(25,58)\n",
        "            plt.xlabel('Latitude')\n",
        "            plt.ylabel('Mean temperature [K]')\n",
        "            plt.grid()\n",
        "            plt.legend(loc='upper right')  \n",
        "            #plt.show()\n",
        "          \n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            im = Image.open(buf)\n",
        "            img = torchvision.transforms.ToTensor()(im)\n",
        "            \n",
        "            self.logger.experiment.add_image(f\"latitudinal_mean\", img, trainer.current_epoch)\n",
        "\n",
        "        if test_data_ is not None and self.plt_hist==True:\n",
        "            data_gan = getattr(test_data_, \"gan\").values.flatten()\n",
        "            data_era5 = getattr(test_data_, \"era5\").values.flatten()\n",
        "            plt.figure()\n",
        "            _ = plt.hist(data_gan,\n",
        "                        bins=100,\n",
        "                        histtype='step',\n",
        "                        log=True,\n",
        "                        label=\"gan\",\n",
        "                        alpha=0.9,\n",
        "                        density=True,\n",
        "                        linewidth=2,\n",
        "                        color=\"red\")\n",
        "            \n",
        "            _ = plt.hist(data_era5,\n",
        "                        bins=100,\n",
        "                        histtype='step',\n",
        "                        log=True,\n",
        "                        label=\"era5\",\n",
        "                        alpha=1,\n",
        "                        density=True,\n",
        "                        linewidth=2,\n",
        "                        color=\"black\")\n",
        "\n",
        "            plt.xlabel('Temperature [K]')\n",
        "            plt.ylabel('Histogram')\n",
        "            plt.xlim(0,400)\n",
        "            plt.grid()\n",
        "            plt.legend(loc='upper right')\n",
        "\n",
        "            #plt.show()\n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            im_ = Image.open(buf)\n",
        "            img_ = torchvision.transforms.ToTensor()(im_)\n",
        "            \n",
        "            self.logger.experiment.add_image(f\"histogram\", img_, trainer.current_epoch)"
      ],
      "metadata": {
        "id": "KpchPItBC6E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Cycle GAN"
      ],
      "metadata": {
        "id": "RO0_lUBIfzaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cycle_gan(config, pretrain_path=False,validation=True,track_lat_mean=False,plt_hist=False ):\n",
        "    \"\"\" Main routing to train the Cycle GAN \"\"\"\n",
        "\n",
        "    config = Config()\n",
        "    global version\n",
        "    version = get_version(config.date,config.time)\n",
        "    print(f'Running model: {version}')\n",
        "    checkpoint_path = get_checkpoint_path(config, version)\n",
        "    set_environment()\n",
        "\n",
        "    tb_logger = TensorBoardLogger(config.tensorboard_path,name=\"\",version=version,default_hp_metric=False)\n",
        "    \n",
        "    create_folder(f\"/content/gdrive/MyDrive/bias_gan/results/{version}\")\n",
        "    save_config(config, version)\n",
        "    \n",
        "    mse_callback = MAE_Callback(tb_logger,checkpoint_path,config,validation,lat_mean=track_lat_mean,plt_hist=plt_hist)\n",
        "    \n",
        "    \n",
        "    trainer = pl.Trainer(callbacks=[mse_callback] + get_cycle_gan_callbacks(checkpoint_path),\n",
        "                         gpus = 1,\n",
        "                         max_epochs = config.epochs,\n",
        "                         precision = 16, \n",
        "                         num_sanity_val_steps = 1,\n",
        "                         logger = tb_logger,\n",
        "                         log_every_n_steps = config.log_every_n_steps,\n",
        "                         deterministic = False,\n",
        "                         accelerator=accelerator,\n",
        "                         enable_model_summary=False) \n",
        "    \n",
        "\n",
        "    datamodule = DataModule(config, training_batch_size = config.train_batch_size, test_batch_size = config.test_batch_size)\n",
        "    datamodule.setup(\"fit\")\n",
        "    \n",
        "    \n",
        "    if pretrain_path==False:\n",
        "      print(\"no pretraining\")\n",
        "      model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
        "                       epoch_decay = config.epochs // 2,running_bias=config.running_bias,num_resnet_blocks=config.num_resnet_layer, default_nbr_resnet=config.default_nbr_resnet)\n",
        "    else:\n",
        "      print(\"using pretrained model with path:\",pretrain_path)\n",
        "      model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
        "                       epoch_decay = config.epochs // 2, running_bias=config.running_bias,num_resnet_blocks=config.num_resnet_layer, default_nbr_resnet=config.default_nbr_resnet).load_from_checkpoint(pretrain_path)\n",
        "\n",
        "    trainer.fit(model, datamodule)\n",
        "\n",
        "    print('Training finished')\n",
        "    return model"
      ],
      "metadata": {
        "id": "efWHPrX2Ck9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "Bq-nYOq2tAfe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDSas-G6yYG1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\" \n",
        "    Training configuration parameters. For model evaluation parameters see\n",
        "    src/configuration.py.\n",
        "    \"\"\"\n",
        "    \n",
        "    scratch_path: str = '/content/gdrive/MyDrive/bias_gan/results'\n",
        "    tensorboard_path: str = f'{scratch_path}/'\n",
        "    checkpoint_path: str = f'{scratch_path}/'\n",
        "    config_path: str = f'{scratch_path}/'\n",
        "    \n",
        "    model_pr_path: str = f\"/content/gdrive/MyDrive/bias_gan/data/detrend_pr_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
        "    era5_pr_path: str = f\"/content/gdrive/MyDrive/bias_gan/data/detrend_pr_W5E5v2.0_regionbox_era5_1979-2014.nc\"\n",
        "    model_t_path: str = f\"/content/gdrive/MyDrive/bias_gan/data/tas_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
        "    era5_t_path: str = f\"/content/gdrive/MyDrive/bias_gan/data/tas_W5E5v2.0_regionbox_1979-2014.nc\"\n",
        "   \n",
        "\n",
        "    results_path: str = f'{scratch_path}/'\n",
        "    projection_path: str = None\n",
        "\n",
        "    train_start: int = 1979\n",
        "    train_end: int = 1980 #2000 \n",
        "    valid_start: int = 2001 #was 2001\n",
        "    valid_end: int = 2004\n",
        "    test_start: int = 2004\n",
        "    test_end: int = 2014\n",
        "    \n",
        "    model_name: str = 'tibet_gan'\n",
        "\n",
        "    epochs: int = 2 # set to 250 for reproduction\n",
        "    progress_bar_refresh_rate: int = 50\n",
        "    train_batch_size: int = 1\n",
        "    test_batch_size: int = 64\n",
        "    transforms: List = field(default_factory=lambda: ['log', 'normalize_minus1_to_plus1'])\n",
        "    transformations = ['log', 'normalize_minus1_to_plus1']\n",
        "    rescale: bool = False\n",
        "    epsilon: float = 0.0001\n",
        "    lazy: bool = False\n",
        "    log_every_n_steps: int = 10 ### was 10\n",
        "    norm_output: bool = True\n",
        "    running_bias: bool = False\n",
        "\n",
        "    d_lr = 2e-4\n",
        "    g_lr = 2e-4\n",
        "    beta_1 = 0.5\n",
        "    beta_2 = 0.999\n",
        "    epoch_decay = 200\n",
        "    \n",
        "\n",
        "    time = datetime.now().time().strftime(\"%Hh_%Mm_%Ss\")\n",
        "    date = datetime.now().date().strftime(\"%Y_%m_%d\")\n",
        "    \n",
        "    default_nbr_resnet=True\n",
        "    num_resnet_layer=6\n",
        "\n",
        "\n",
        "def main():\n",
        "    _ = train_cycle_gan(Config())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run"
      ],
      "metadata": {
        "id": "BuE3z8TfEMhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "do_training = True\n",
        "from_skratch = True\n",
        "\n",
        "track_lat_mean = True\n",
        "plt_hist=True\n",
        "\n",
        "runtime_instance = \"2023_02_10_10h_26m_48s\"\n",
        "\n",
        "if do_training == True:\n",
        "    accelerator=\"gpu\"\n",
        "\n",
        "    if from_skratch == True:\n",
        "        train_cycle_gan(Config(),validation=False,track_lat_mean=track_lat_mean,plt_hist=plt_hist)\n",
        "        \n",
        "\n",
        "    if from_skratch == False:\n",
        "        train_cycle_gan(Config(),f\"/content/gdrive/MyDrive/bias_gan/results/{runtime_instance}/last.ckpt\",validation=True,track_lat_mean=track_lat_mean,plt_hist=plt_hist)"
      ],
      "metadata": {
        "id": "Cid_5UwLyttz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model_"
      ],
      "metadata": {
        "id": "jHK2KTgauqDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model_ = xr.open_dataset(Config.poem_path)\n",
        "climate_model_.tas.values.shape"
      ],
      "metadata": {
        "id": "PbuFdUw4AcKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model = xr.open_dataset(Config.era5_path)\n",
        "climate_model.tas.values.shape"
      ],
      "metadata": {
        "id": "MZig-jepR5s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorboard logging"
      ],
      "metadata": {
        "id": "au8YMzdenH1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "-C07ecZu8qKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if do_training==True: \n",
        "    %tensorboard --logdir /content/gdrive/MyDrive/bias_gan/results/{version}/"
      ],
      "metadata": {
        "id": "T6I1AxV4Y3Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if do_training==False: \n",
        "  %tensorboard --logdir /content/gdrive/MyDrive/bias_gan/results/{runtime_instance}/"
      ],
      "metadata": {
        "id": "7BBG_ha-qWOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save images from tensorboard files to drive"
      ],
      "metadata": {
        "id": "gAnl0A4nBRxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_images_for_gif = False\n",
        "\n",
        "\n",
        "def save_tensorboard_images(event_file, outdir):\n",
        "    event_acc = event_accumulator.EventAccumulator(event_file, size_guidance={'images': 0})\n",
        "    event_acc.Reload()\n",
        "\n",
        "    outdir = pathlib.Path(outdir)\n",
        "    outdir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    for tag in event_acc.Tags()['images']:\n",
        "        events = event_acc.Images(tag)\n",
        "\n",
        "        tag_name = tag.replace('/', '_')\n",
        "        dirpath = outdir / tag_name\n",
        "        dirpath.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "        for index, event in enumerate(events):\n",
        "            s = np.frombuffer(event.encoded_image_string, dtype=np.uint8)\n",
        "            image = cv2.imdecode(s, cv2.IMREAD_COLOR)\n",
        "            #outpath = dirpath / '{:04}.jpg'.format(index) \n",
        "            outpath = dirpath / '{:04}.jpg'.format(index+239)\n",
        "            cv2.imwrite(outpath.as_posix(), image)\n",
        "\n",
        "\n",
        "\n",
        "if save_images_for_gif == True:\n",
        "    path_to_event_file = '/content/gdrive/MyDrive/bias_gan/results/2023_02_02_10h_51m_31s/events.out.tfevents.1675331519.gpu-001.2945388.0'\n",
        "    outdir = \"/content/gdrive/MyDrive/bias_gan/results/2023_02_02_10h_51m_31s\"\n",
        "    save_tensorboard_images(path_to_event_file, outdir)"
      ],
      "metadata": {
        "id": "t5Q2Rfc63KGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/MyDrive/bias_gan/results/latitudinal_mean\""
      ],
      "metadata": {
        "id": "SBN8GgyGrbRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get MAE"
      ],
      "metadata": {
        "id": "oqGDAuCARcGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Config_adjusted_trafo = Config\n",
        "Config_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\n",
        "len_training_dataset = len(CycleDataset('train', Config_adjusted_trafo))\n",
        "len_valid_dataset = len(CycleDataset('valid', Config_adjusted_trafo))\n",
        "len_test_dataset = len(CycleDataset('test', Config_adjusted_trafo))\n",
        "\n",
        "len_training_dataset, len_valid_dataset, len_test_dataset"
      ],
      "metadata": {
        "id": "sB1qvReJWBZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_mae_training_fragments = False\n",
        "if combine_mae_training_fragments:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.python.summary.summary_iterator import summary_iterator\n",
        "    epochs_0 = []\n",
        "    mae_values_0 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_01_19_16h_26m_23s/events.out.tfevents.1674145623.c0c1f3e09513.1224.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_0.append(e.step/len_training_dataset)\n",
        "                mae_values_0.append(v.simple_value)\n",
        "\n",
        "    \"\"\"\n",
        "    plt.plot(epochs_0, mae_values_0)\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"MAE\")\n",
        "    plt.title(\"MAE VS EPOCHS validation\")\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "\n",
        "    epochs_1 = []\n",
        "    mae_values_1 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_01_31_10h_24m_37s/events.out.tfevents.1675157093.dgx-002.1451939.4'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_1.append(e.step/len_training_dataset)\n",
        "                mae_values_1.append(v.simple_value)\n",
        "\n",
        "    epochs_2 = []\n",
        "    mae_values_2 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_01_31_19h_24m_28s/events.out.tfevents.1675189486.dgx-002.1619062.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_2.append(e.step/len_training_dataset)\n",
        "                mae_values_2.append(v.simple_value)\n",
        "\n",
        "\n",
        "    epochs_3 = []\n",
        "    mae_values_3 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_02_01_16h_44m_03s/events.out.tfevents.1675266262.dgx-002.1953755.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_3.append(e.step/len_training_dataset)\n",
        "                mae_values_3.append(v.simple_value)            \n",
        "\n",
        "    epochs_4 = []\n",
        "    mae_values_4 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_02_02_08h_29m_00s/events.out.tfevents.1675322959.dgx-002.2208864.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_4.append(e.step/len_training_dataset)\n",
        "                mae_values_4.append(v.simple_value)\n",
        "\n",
        "    epochs_5 = []\n",
        "    mae_values_5 = []\n",
        "\n",
        "    for e in summary_iterator('/content/gdrive/MyDrive/bias_gan/results/2023_02_02_10h_51m_31s/events.out.tfevents.1675331519.gpu-001.2945388.0'):\n",
        "        for v in e.summary.value:\n",
        "            if v.tag == 'MAE':\n",
        "                epochs_5.append(e.step/len_training_dataset)\n",
        "                mae_values_5.append(v.simple_value)\n",
        "\n",
        "\n",
        "    epoch_total = epochs_0 + [69+i for i in epochs_1] + [69+34+i for i in epochs_2] +[69+34+65+i for i in epochs_3]+[69+34+65+59+i for i in epochs_4]+[69+34+65+59+7+i for i in epochs_5]\n",
        "    mae_total = mae_values_0 + mae_values_1 + mae_values_2 + mae_values_3 + mae_values_4 +mae_values_5\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(epoch_total, mae_total)\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"MAE\")\n",
        "    plt.title(\"MAE VS EPOCHS validation\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WdTyNs2GYYYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make gifs\n"
      ],
      "metadata": {
        "id": "jN5-KFkOAlKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def create_gif(images_folder, gif_name, duration=0.7):\n",
        "    images = []\n",
        "    filenames = sorted((images_folder).glob(\"*.jpg\"))\n",
        "    for filename in filenames:\n",
        "        images.append(imageio.imread(filename))\n",
        "    imageio.mimsave(gif_name, images, duration=duration)"
      ],
      "metadata": {
        "id": "lZHuZsiW_etN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_gif = False\n",
        "\n",
        "# create gif and save to the current directory\n",
        "gif_name = '/content/gdrive/MyDrive/bias_gan/results/histogram.gif'\n",
        "images_folder = pathlib.Path(\"/content/gdrive/MyDrive/bias_gan/results/histograms_combined\")\n",
        "\n",
        "if create_gif == True:\n",
        "    create_gif(images_folder, gif_name)\n",
        "    # show the gif in colab\n",
        "    from IPython.display import Image\n",
        "    with open(gif_name,'rb') as f:\n",
        "        display(Image(data=f.read()))"
      ],
      "metadata": {
        "id": "6xjbNbXbAjsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create gif and save to the current directory\n",
        "gif_name = '/content/gdrive/MyDrive/bias_gan/results/latitudinal_mean.gif'\n",
        "images_folder = pathlib.Path(\"/content/gdrive/MyDrive/bias_gan/results/latitudinal_mean\")\n",
        "\n",
        "if create_gif == True:\n",
        "    create_gif(images_folder, gif_name)\n",
        "    # show the gif in colab\n",
        "    from IPython.display import Image\n",
        "    with open(gif_name,'rb') as f:\n",
        "        display(Image(data=f.read()))"
      ],
      "metadata": {
        "id": "jPI5K0BB_73k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "2adJLjPo-15I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Evaluation\n"
      ],
      "metadata": {
        "id": "VGpAmsXwFzjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if do_training==False: \n",
        "  version_ = runtime_instance\n",
        "else:\n",
        "  version_ = version\n",
        "\n",
        "\n",
        "checkpoint_path = f\"/content/gdrive/MyDrive/bias_gan/results/{version_}/last.ckpt\" \n",
        "config_path = f\"/content/gdrive/MyDrive/bias_gan/results/{version_}/config_model.json\"\n",
        "\n",
        "data = EvaluateCheckpoints(checkpoint_path=checkpoint_path, config_path=config_path, save_model=True, version=version_)"
      ],
      "metadata": {
        "id": "LeBFJMy3-NSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data, reconstruct_data = data.run()\n",
        "test_data = data.get_test_data()"
      ],
      "metadata": {
        "id": "2VuJjIiTjpnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average absolute error\n",
        "avg_gan = np.round(np.sum(abs(test_data.era5.values - inv_transform(test_data.gan.values.squeeze())))/(4018*60*118),2)\n",
        "print(\"average absolute differnce in tas values obs-gan:\",avg_gan)\n",
        "\n",
        "#average absolute error\n",
        "avg_cm = np.round(np.sum(abs(test_data.era5.values - test_data.climate_model.values))/(4018*60*118),2)\n",
        "print(\"average absolute differnce in tas values obs-cm:\",avg_cm)"
      ],
      "metadata": {
        "id": "IWsZqEQSb7QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edata_era5 = test_data.era5.values.mean(axis=(0,2))\n",
        "\n",
        "#data_gan= inv_transform(test_data.gan.values.squeeze()).mean(axis=(0,2))\n",
        "data_gan = inv_transform(test_data.gan, climate_model_reference).squeeze().mean(axis=(0,2))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(test_data.gan.lat, data_gan,\n",
        "          label=\"gan\",\n",
        "          alpha=0.9,\n",
        "          linestyle='-',\n",
        "          linewidth=2,\n",
        "          color=\"red\")\n",
        "\n",
        "\n",
        "plt.plot(test_data.era5.lat, data_era5,\n",
        "          label=\"era5\",\n",
        "          alpha=1,\n",
        "          linestyle='--',\n",
        "          linewidth=2,\n",
        "          color=\"black\")\n",
        "plt.xlim(25,58)\n",
        "plt.xlabel('Latitude')\n",
        "plt.ylabel('Mean temperature [K]')\n",
        "plt.grid()\n",
        "plt.legend(loc='upper right')  \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N05Qp2BGvC3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_gan= inv_transform(test_data.gan.values.squeeze()).mean(axis=(0,2))\n",
        "data_gan = inv_transform(test_data.gan, climate_model_reference).squeeze().mean(axis=(0,2))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(test_data.gan.lat, data_gan,\n",
        "          label=\"gan\",\n",
        "          alpha=0.9,\n",
        "          linestyle='-',\n",
        "          linewidth=2,\n",
        "          color=\"red\")\n",
        "\n",
        "\n",
        "plt.xlim(25,58)\n",
        "plt.xlabel('Latitude')\n",
        "plt.ylabel('Mean temperature [K]')\n",
        "plt.grid()\n",
        "plt.legend(loc='upper right')  \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CAQf3HBSKZx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_climate_model_reference_data():\n",
        "\n",
        "        climate_model = xr.open_dataset(Config.poem_path)\n",
        "\n",
        "        if 'poem_precipitation' in climate_model.variables:\n",
        "            climate_model =  climate_model.poem_precipitation\n",
        "        else:\n",
        "            climate_model =  climate_model.precipitation\n",
        "\n",
        "        if not Config.lazy:\n",
        "            climate_model = climate_model.load()\n",
        "\n",
        "        climate_model = climate_model.sel(time=slice(str(Config.train_start), str(Config.train_end)))\n",
        "\n",
        "        return climate_model"
      ],
      "metadata": {
        "id": "41L73-wJGb6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_climate_model_data( is_reference=False):\n",
        "        \"\"\" Y-domain samples \"\"\"\n",
        "\n",
        "        stage = \"test\"\n",
        "        splits = {\n",
        "                \"train\": [str(Config.train_start), str(Config.train_end)],\n",
        "                \"valid\": [str(Config.valid_start), str(Config.valid_end)],\n",
        "                \"test\":  [str(Config.test_start), str(Config.test_end)],\n",
        "        }\n",
        "\n",
        "\n",
        "        climate_model = xr.open_dataset(Config.poem_path,\n",
        "                                        cache=True, chunks=None)\n",
        "\n",
        "        if 'poem_precipitation' in climate_model.variables:\n",
        "            climate_model =  climate_model.tas\n",
        "        else:\n",
        "            climate_model =  climate_model.tas\n",
        "\n",
        "        if not Config.lazy:\n",
        "            climate_model = climate_model.load()\n",
        "\n",
        "        if is_reference:\n",
        "            climate_model = climate_model.sel(time=slice(splits['train'][0],\n",
        "                                                         splits['train'][1]))\n",
        "        else:\n",
        "            climate_model = climate_model.sel(time=slice(splits[stage][0],\n",
        "                                                         splits[stage][1]))\n",
        "\n",
        "        return climate_model"
      ],
      "metadata": {
        "id": "J-q4qbwBHvqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Config.transforms"
      ],
      "metadata": {
        "id": "SwG7BD0NLJLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_transforms( data, data_ref):\n",
        "\n",
        "        if 'log' in Config.transforms:\n",
        "            data = log_transform(data, epsilon)\n",
        "            data_ref = log_transform(data_ref, epsilon)\n",
        "\n",
        "        if 'normalize' in Config.transforms:\n",
        "            data = norm_transform(data, data_ref)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in Config.transforms:\n",
        "            data = norm_minus1_to_plus1_transform(data, data_ref)\n",
        "        \n",
        "        return data"
      ],
      "metadata": {
        "id": "LUbUJ2PaGPxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon=0.0001\n",
        "\n",
        "climate_model = load_climate_model_data()\n",
        "climate_model_reference = load_climate_model_data(is_reference=True)\n",
        "\n",
        "#era5 = load_era5_data()\n",
        "#era5_reference = load_era5_data(is_reference=True)\n",
        "#era5 = apply_transforms(era5, era5_reference)\n",
        "\n",
        "climate_model_ = apply_transforms(climate_model, climate_model_reference)"
      ],
      "metadata": {
        "id": "wY2EbtdpHeta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model,inv_transform(climate_model_,climate_model_reference)"
      ],
      "metadata": {
        "id": "V9WMbmDaLvwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climate_model.shape"
      ],
      "metadata": {
        "id": "Pl7ITwQbLEHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4018*60*118"
      ],
      "metadata": {
        "id": "H7NGmPW1LJdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(np.round(climate_model,0) == np.round(inv_transform(climate_model_,climate_model_reference),0))-28447440"
      ],
      "metadata": {
        "id": "Lh7veIHAK7fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create reconstructions"
      ],
      "metadata": {
        "id": "Dxf0UZB5Komf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Config_adjusted_trafo = Config\n",
        "Config_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\n",
        "dataset = CycleDataset('train', Config_adjusted_trafo)"
      ],
      "metadata": {
        "id": "g5OZ8gZ5Luyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " nbr_reconstruction_examples = 2"
      ],
      "metadata": {
        "id": "1ZkFP4HVuJ_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define inverse transformation and define forward/backward models"
      ],
      "metadata": {
        "id": "HwHZWZGZKz6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, generator_model: torch.nn.Module, constrain=True):\n",
        "        super(Generator, self).__init__()\n",
        "        self.generator =  generator_model\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.generator(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "bvm--uyQ9__7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inv_transform(data, reference=None):\n",
        "        \"\"\" The output equals ERA5, therefore it needs to be\n",
        "            constraind with respect to it\n",
        "        \"\"\"\n",
        "        if reference is None:\n",
        "            reference = xr.open_dataset(Config.era5_path).tas.sel(time=slice(str(Config.train_start), str(Config.train_end))).values\n",
        "\n",
        "        if 'log' in Config.transformations:\n",
        "            reference = log_transform(reference, Config.epsilon)\n",
        "\n",
        "        if 'normalize' in Config.transformations:\n",
        "            data = inv_norm_transform(data, reference)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in Config.transformations:\n",
        "            data = inv_norm_minus1_to_plus1_transform(data, reference)\n",
        "\n",
        "        if 'log' in Config.transformations:\n",
        "            data = inv_log_transform(data, Config.epsilon)\n",
        "\n",
        "        return data\n",
        "\n",
        "ckpt_path = Config.checkpoint_path + f\"{version_}\" +\"/last.ckpt\"\n",
        "\n",
        "model_fw = CycleGAN().load_from_checkpoint(checkpoint_path=ckpt_path)\n",
        "model_fw.freeze()\n",
        "model_fw = model_fw.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "model_fw = Generator(model_fw.g_B2A, constrain=False)\n",
        "\n",
        "\n",
        "model_bw = CycleGAN().load_from_checkpoint(checkpoint_path=ckpt_path)\n",
        "model_bw.freeze()\n",
        "model_bw = model_bw.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "model_bw = Generator(model_bw.g_A2B, constrain=False)"
      ],
      "metadata": {
        "id": "Uqoma3efKsr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reconstruction starting with climate model"
      ],
      "metadata": {
        "id": "Tyc4ELg9K5Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(nbr_reconstruction_examples):\n",
        "    test_data_ = dataset[i]  \n",
        "\n",
        "    obs = test_data_['B'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))   \n",
        "    gan = model_fw(obs)\n",
        "    rec = model_bw(gan)\n",
        "\n",
        "    #print(np.array(obs.cpu()))\n",
        "    #print( climate_model_reference)\n",
        "    #data_obs = inv_transform(np.array(obs.cpu()),climate_model_reference).squeeze()\n",
        "    data_obs = inv_transform(obs.squeeze().cpu())\n",
        "    data_gan = inv_transform(gan.squeeze().cpu())\n",
        "    data_rec = inv_transform(rec.squeeze().cpu())\n",
        "\n",
        "    print(\"average predicted error in temperature:\",np.round(torch.sum(abs(data_obs-data_gan).cpu())/(60*118),0),\"degrees K\")\n",
        "\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    cs = ax[0].pcolormesh(data_obs.squeeze().cpu())\n",
        "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
        "    sm = plt.cm.ScalarMappable(norm=norm)\n",
        "    sm.set_array([])\n",
        "\n",
        "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
        "    ax[0].set_title(\"climate model data\")\n",
        "\n",
        "    cs = ax[1].pcolormesh(data_gan.squeeze().cpu() )#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
        "    ax[1].set_title(\"generated observation (gan)\")\n",
        "\n",
        "    cs = ax[2].pcolormesh(data_rec.squeeze().cpu() ) #, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
        "    ax[2].set_title(\"reconstruction of climate model data\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eVaBt7A3K6Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reconstruction starting with observations"
      ],
      "metadata": {
        "id": "4NBbOL6iLC73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(nbr_reconstruction_examples):\n",
        "    test_data_ = dataset[i]  \n",
        "\n",
        "    model = test_data_['A'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))   \n",
        "    gan = model_fw(model)\n",
        "    rec = model_bw(gan)\n",
        "\n",
        "    data_model = inv_transform(model.squeeze().cpu())#*3600*24\n",
        "    data_gan = inv_transform(gan.squeeze().cpu())#*3600*24\n",
        "    data_rec = inv_transform(rec.squeeze().cpu())#*3600*24\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    cs = ax[0].pcolormesh(data_model.squeeze().cpu())#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
        "    ax[0].set_title(\"observation data\")\n",
        "\n",
        "    cs = ax[1].pcolormesh(data_gan.squeeze().cpu())#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
        "    ax[1].set_title(\"generated climate model data (gan)\")\n",
        "\n",
        "    cs = ax[2].pcolormesh(data_rec.squeeze().cpu())#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
        "    ax[2].set_title(\"reconstruction of observation data\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JJP2BpKVLIR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot  **frames**"
      ],
      "metadata": {
        "id": "rOMdYqIrEBEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot single frames"
      ],
      "metadata": {
        "id": "aAh6JIg0nCC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "set the chose_day parameter to plot the precipitation on a specific day"
      ],
      "metadata": {
        "id": "o7NrV7zfnELz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chose_day=10\n",
        "\n",
        "PlotAnalysis(test_data).single_frames(time_index=chose_day)\n",
        "PlotAnalysis(test_data).single_frames(projection=\"cyl\",time_index=chose_day)"
      ],
      "metadata": {
        "id": "UdNmJG-jHyGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot of the average test_data for each data"
      ],
      "metadata": {
        "id": "rInMTAV9t7jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PlotAnalysis(test_data).avg_frames(projection=\"cyl\",scale_precip_by = 10)"
      ],
      "metadata": {
        "id": "04wEV8jGnfkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot of the average **errors** between era5 & gan / climate_model"
      ],
      "metadata": {
        "id": "dZrUokXJuHxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PlotAnalysis(test_data).avg_frames_abs_err(projection=\"cyl\", scale_precip_by = 20)"
      ],
      "metadata": {
        "id": "xLvmxOQVgsqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**: plot spatial plot - mean Error - also show lands"
      ],
      "metadata": {
        "id": "M5e8_eN2Ggk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot **histogram** statistics\n",
        "Precipitation rates averaged over time and longitudes and relative frequency histograms"
      ],
      "metadata": {
        "id": "lXihevAlFamY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## histogram no log"
      ],
      "metadata": {
        "id": "O9B4JKnll_iR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we plot the histogram over the daily precipitation values in the test dataset. "
      ],
      "metadata": {
        "id": "EfvPYKo3QKg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(4, 4),  constrained_layout=True)\n",
        "\n",
        "PlotAnalysis(test_data).histograms(single_plot=False, ax=ax, show_legend=True, annotate=True,log=False,xlim_end=30)"
      ],
      "metadata": {
        "id": "gNlHXpskQVoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## histogram log on **density**"
      ],
      "metadata": {
        "id": "Et2xtAYKmCfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because it is hard to see anything because precipitations over 50 are very rare and thus the 3 plots are right above eachother, we apply the log to the probability desnity to better see the differences."
      ],
      "metadata": {
        "id": "QYgwpz8CQYYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "\n",
        "PlotAnalysis(test_data).histograms(single_plot=False, ax=ax, show_legend=True, annotate=True,log=True)"
      ],
      "metadata": {
        "id": "fmVwmg1G3-Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot histogram log density **differences**"
      ],
      "metadata": {
        "id": "b5VbVeqyF92W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "days in the test_data set"
      ],
      "metadata": {
        "id": "PyzvlWO2Lsaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(getattr(test_data,\"gan\").time)"
      ],
      "metadata": {
        "id": "VQ4w2of3LT6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "\n",
        "PlotAnalysis(test_data).histogram_diff(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ],
      "metadata": {
        "id": "m60e1vv6F-B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot log **precipitation**"
      ],
      "metadata": {
        "id": "nolk4FVNloC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying the **log** to the data itself instead of to the amount of points in the bins as in the plot before results in the density to be on one scale:"
      ],
      "metadata": {
        "id": "zUlODjL9PuRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "PlotAnalysis(test_data).log_histograms(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ],
      "metadata": {
        "id": "wX7CMfFUE-JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot histogram log precipitation differences"
      ],
      "metadata": {
        "id": "jbqJBrV8O3un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PlotAnalysis(test_data).log_histogram_diff(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ],
      "metadata": {
        "id": "qp7f8K0nO-a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot **latitudinal** **mean**"
      ],
      "metadata": {
        "id": "tJEOwVMmFkZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PlotAnalysis(test_data).latitudinal_mean()"
      ],
      "metadata": {
        "id": "DkWfYREj2shn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#try loading finished gan world"
      ],
      "metadata": {
        "id": "z4WBVpYz12aZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## new cyclegan model code"
      ],
      "metadata": {
        "id": "2VU5Nw1XryeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load new model: "
      ],
      "metadata": {
        "id": "yxdRevxDrseD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#state_dict = torch.load(\"/content/gdrive/MyDrive/bias_gan/results/pretrained_gan_world/last.ckpt\",map_location=torch.device('cpu'))\n",
        "#CycleGAN(num_resnet_layer = 7).load_state_dict(state_dict, strict=False)"
      ],
      "metadata": {
        "id": "0X9prBKKNM_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SSIM comparison"
      ],
      "metadata": {
        "id": "y8PqETITpXRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Open the .nc file\n",
        "data_gan = xr.open_dataset(f'/content/gdrive/MyDrive/bias_gan/results/{version_}/gan.nc').gan_precipitation\n",
        "data_era5 = xr.open_dataset(f\"/content/gdrive/MyDrive/bias_gan/data_gan/pr_W5E5v2.0_regionbox_era5_1979-2014.nc\").era5_precipitation #*3600*24 \n",
        "data_model = xr.open_dataset(f\"/content/gdrive/MyDrive/bias_gan/data_gan/pr_gfdl-esm4_historical_regionbox_1979-2014.nc\").precipitation #*3600*24 \n",
        "\n",
        "# Extract the data you want to calculate SSIM for\n",
        "gan_values = data_gan.values\n",
        "era5_values = data_era5.values\n",
        "model_values = data_model.values"
      ],
      "metadata": {
        "id": "YlKppGu7pY4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate the SSIM for the gan only for 4018 entries bc thats the size of the test dataset"
      ],
      "metadata": {
        "id": "4owxn8PdRjQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SSIM for the climate model"
      ],
      "metadata": {
        "id": "fS2t5DtwR1xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate SSIM\n",
        "model_score, model_diff = ssim(era5_values[-4018:,:,:], model_values[-4018:,:,:], full=True)\n",
        "print(\"model score:\", model_score)"
      ],
      "metadata": {
        "id": "TXUNamb4RzRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SSIM for the GAN"
      ],
      "metadata": {
        "id": "dSVlMhL0SFhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gan_score, gan_diff = ssim(era5_values[-4018:,:,:], gan_values, full=True)\n",
        "print(\"gan score:\", gan_score)"
      ],
      "metadata": {
        "id": "uTP5aLojNnkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan_values.shape,era5_values.shape,model_values.shape"
      ],
      "metadata": {
        "id": "jneyCa-iQ6HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare metrics"
      ],
      "metadata": {
        "id": "uzy2NsxwlnK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "instances = [\"2023_01_11_13h_04m_08s\",\"2023_01_12_05h_34m_48s\",\"2023_01_12_07h_34m_09s\",\"2023_01_13_07h_17m_53s\", \"2023_01_13_11h_06m_15s\",\"2023_01_14_08h_45m_11s\"]\n",
        "\n",
        "for i in instances: \n",
        "    evaluation_instance = i\n",
        "    checkpoint_path = f\"/content/gdrive/MyDrive/bias_gan/results/{evaluation_instance}/last.ckpt\" \n",
        "    config_path = f\"/content/gdrive/MyDrive/bias_gan/results/{evaluation_instance}/config_model.json\"\n",
        "    data = EvaluateCheckpoints(checkpoint_path=checkpoint_path, config_path=config_path, save_model=True)\n",
        "    data.run()\n",
        "    test_data = data.get_test_data()\n",
        "    print(\"\")\n",
        "    PlotAnalysis(test_data).avg_frames_abs_err(projection=\"cyl\", scale_precip_by = 10)\n",
        "    print(\"\")\n",
        "    PlotAnalysis(test_data).latitudinal_mean()\n",
        "    print(\"\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jX2K86s_lmdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data: raw output\n",
        "# check whats available in isimip\n",
        "\n",
        "\n",
        "# do we use the right data? the already bias corrected data (also with downscaling)\n",
        "\n",
        "# downscaled climate model"
      ],
      "metadata": {
        "id": "kcl90dmF9pKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. remove all trends and add again at the end !!!\n",
        "# 2. "
      ],
      "metadata": {
        "id": "pm0eVqjH92Es"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}