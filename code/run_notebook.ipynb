{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h3yHWmlizCSY",
        "ecz59xDYFx7c"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/Bias_GAN/blob/master/code/run_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ],
      "metadata": {
        "id": "h3yHWmlizCSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "#%cd \"/content/gdrive/MyDrive/data_gan\""
      ],
      "metadata": {
        "id": "pM43-ErszEe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aim56009/Bias_GAN.git"
      ],
      "metadata": {
        "id": "UabaOuiKzJtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pytorch_lightning\n",
        "!pip install basemap"
      ],
      "metadata": {
        "id": "yg_fJ3Fi0rzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install importlib-metadata==4.0.1\n",
        "!pip install xarray==0.18.1"
      ],
      "metadata": {
        "id": "zGlKJUfZe1Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import ArgumentParser\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List\n",
        "import getpass\n",
        "\n",
        "#from Bias_GAN.code.src.trainer import train_cycle_gan"
      ],
      "metadata": {
        "id": "ctpYd5RO0GJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "BDZR-hows48Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import json\n",
        "\n",
        "from Bias_GAN.code.src.model import CycleGAN\n",
        "from Bias_GAN.code.src.data import DataModule\n",
        "from Bias_GAN.code.src.utils import get_version, set_environment, get_checkpoint_path, save_config\n",
        "from Bias_GAN.code.src.callbacks import get_cycle_gan_callbacks"
      ],
      "metadata": {
        "id": "IRy8p9GeConu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cycle_gan(config, pretrain_path=False):\n",
        "    \"\"\" Main routing to train the Cycle GAN \"\"\"\n",
        "    \n",
        "    config = Config()\n",
        "    version = get_version()\n",
        "    print(f'Running model: {version}')\n",
        "    checkpoint_path = get_checkpoint_path(config, version)\n",
        "    \n",
        "    set_environment()\n",
        "    print(\"checkpoint_path before:\",checkpoint_path) \n",
        "    tb_logger = TensorBoardLogger(config.tensorboard_path,\n",
        "                           name=config.model_name,\n",
        "                           default_hp_metric=False,\n",
        "                           version = checkpoint_path)\n",
        "                           #version = version\n",
        "\n",
        "    trainer = pl.Trainer(gpus = 1,\n",
        "                         max_epochs = config.epochs,\n",
        "                         precision = 16, \n",
        "                         #progress_bar_refresh_rate = config.progress_bar_refresh_rate,\n",
        "                         callbacks = get_cycle_gan_callbacks(checkpoint_path),\n",
        "                         num_sanity_val_steps = 1,\n",
        "                         logger = tb_logger,\n",
        "                         log_every_n_steps = config.log_every_n_steps,\n",
        "                         deterministic = False,\n",
        "                         accelerator=accelerator) \n",
        "\n",
        "    datamodule = DataModule(config, training_batch_size = config.train_batch_size,\n",
        "                                    test_batch_size = config.test_batch_size)\n",
        "\n",
        "    datamodule.setup(\"fit\")\n",
        "\n",
        "    \n",
        "    \n",
        "    if pretrain_path==False:\n",
        "      print(\"no pretraining\")\n",
        "      model = CycleGAN(epoch_decay = config.epochs // 2,running_bias=config.running_bias)\n",
        "    else:\n",
        "      print(\"using pretrained model with path:\",pretrain_path)\n",
        "      model = CycleGAN(epoch_decay = config.epochs // 2,running_bias=config.running_bias).load_from_checkpoint(pretrain_path)\n",
        "\n",
        "    trainer.fit(model, datamodule)\n",
        "\n",
        "    save_config(config, version)\n",
        "    print('Training finished')\n",
        "    return model"
      ],
      "metadata": {
        "id": "efWHPrX2Ck9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "Bq-nYOq2tAfe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDSas-G6yYG1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\" \n",
        "    Training configuration parameters. For model evaluation parameters see\n",
        "    src/configuration.py.\n",
        "    \"\"\"\n",
        "    \n",
        "    scratch_path: str = '/content/gdrive/MyDrive/bias_gan/results'\n",
        "    tensorboard_path: str = f'{scratch_path}/'\n",
        "    checkpoint_path: str = f'{scratch_path}/'\n",
        "    config_path: str = f'{scratch_path}/'\n",
        "    poem_path: str = f\"/content/gdrive/MyDrive/bias_gan/data_gan/pr_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
        "    era5_path: str = f\"/content/gdrive/MyDrive/bias_gan/data_gan/pr_W5E5v2.0_regionbox_era5_1979-2014.nc\"\n",
        "   \n",
        "\n",
        "    results_path: str = f'{scratch_path}/'\n",
        "    projection_path: str = None\n",
        "\n",
        "    train_start: int = 1979\n",
        "    train_end: int = 1980 # set to 2000 for full run\n",
        "    valid_start: int = 2004 #was 2001\n",
        "    valid_end: int = 2004\n",
        "    test_start: int = 2004\n",
        "    test_end: int = 2014\n",
        "    \n",
        "    model_name: str = 'tibet_gan'\n",
        "\n",
        "    epochs: int = 2 # set to 250 for reproduction\n",
        "    progress_bar_refresh_rate: int = 1\n",
        "    train_batch_size: int = 1\n",
        "    test_batch_size: int = 64\n",
        "    transforms: List = field(default_factory=lambda: ['log', 'normalize_minus1_to_plus1'])\n",
        "    rescale: bool = False\n",
        "    epsilon: float = 0.0001\n",
        "    lazy: bool = False\n",
        "    log_every_n_steps: int = 2 ### was 10\n",
        "    norm_output: bool = True\n",
        "    running_bias: bool = False\n",
        "\n",
        "\n",
        "def main():\n",
        "    _ = train_cycle_gan(Config())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "3cAL47h6s7RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "do_training = False\n",
        "\n",
        "\n",
        "if do_training == True:\n",
        "    accelerator=\"gpu\"\n",
        "\n",
        "    ###### for doing a new run ######\n",
        "    train_cycle_gan(Config())\n",
        "\n",
        "    ###### for running a pretrained checkpoint ######\n",
        "    #train_cycle_gan(Config(),\"/content/gdrive/MyDrive/bias_gan/results/2023_01_05_12h_30m_56s/last.ckpt\")\n"
      ],
      "metadata": {
        "id": "Cid_5UwLyttz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "z-ykm_eB95pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference"
      ],
      "metadata": {
        "id": "We_xzajk-9xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Inference():\n",
        "\n",
        "    \"\"\" Execute model on test data and return output as NetCDF. \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 config,\n",
        "                 constrain=False,\n",
        "                 projection=False,\n",
        "                 projection_path=None,\n",
        "                 max_num_inference_steps=None):\n",
        "        \n",
        "\n",
        "        self.config = config\n",
        "        self.constrain = constrain\n",
        "        self.results_path = config.results_path\n",
        "\n",
        "        self.poem = xr.open_dataset(self.config.poem_path)\n",
        "        self.era5 = xr.open_dataset(self.config.era5_path)\n",
        "\n",
        "        self.train_start = str(config.train_start)\n",
        "        self.train_end = str(config.train_end)\n",
        "        self.test_start = str(config.test_start)\n",
        "        self.test_end = str(config.test_end)\n",
        "        self.epsilon = config.epsilon\n",
        "        self.projection = projection\n",
        "        self.projection_path = projection_path\n",
        "\n",
        "        self.model = None\n",
        "        self.model_output = None\n",
        "        self.dataset = None\n",
        "\n",
        "        self.transforms = config.transforms\n",
        "        self.max_num_inference_steps = max_num_inference_steps\n",
        "        self.tst_batch_sz = 64\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        \n",
        "    def load_model(self, checkpoint_path):\n",
        "    \n",
        "        model = CycleGAN().load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "        model.freeze()\n",
        "        self.model = model.to(self.device)\n",
        "        self.model = ConstrainedGenerator(self.model.g_B2A, constrain=self.constrain)\n",
        "\n",
        "\n",
        "    def get_model(self):\n",
        "        return self.model \n",
        "\n",
        "        \n",
        "    def get_dataloader(self):\n",
        "\n",
        "        #datamodule = DataModule(self.config,\n",
        "        #                        trn_batch_sz = 1,\n",
        "        #                        tst_batch_sz = self.tst_batch_sz)\n",
        "        datamodule = DataModule(self.config,\n",
        "                                training_batch_size = 1,\n",
        "                                test_batch_size = self.tst_batch_sz)\n",
        "        if self.projection:\n",
        "            print('running projection')\n",
        "            datamodule.setup(\"predict\")\n",
        "        else:\n",
        "            datamodule.setup(\"test\")\n",
        "        dataloader = datamodule.test_dataloader()\n",
        "\n",
        "        return dataloader\n",
        "\n",
        "    def get_projection_dataloader(self):\n",
        "\n",
        "        dataloader = ProjectionDataset(self.config)\n",
        "        return dataloader\n",
        "    \n",
        "        \n",
        "    def compute(self):\n",
        "        \"\"\" Use B (ESM) -> A (ERA5) generator for inference \"\"\"\n",
        "\n",
        "        test_data = self.get_dataloader()\n",
        "\n",
        "        data = []\n",
        "\n",
        "        print(\"Start inference:\")\n",
        "        for idx, sample in enumerate(test_data):\n",
        "            sample = sample['B'].to(self.device)\n",
        "            yhat = self.model(sample)\n",
        "\n",
        "            data.append(yhat.squeeze().cpu())\n",
        "            if self.max_num_inference_steps is not None:\n",
        "                if idx > self.max_num_inference_steps - 1:\n",
        "                    break\n",
        "            \n",
        "        self.model_output = torch.cat(data)\n",
        "\n",
        "\n",
        "    def test(self):\n",
        "        dataset = CycleDataset('test', self.config)\n",
        "        test_data = dataset[0]\n",
        "        sample = test_data['A'][0]\n",
        "        data = self.inv_transform(sample)\n",
        "        print(data.min(), data.max())\n",
        "\n",
        "    \n",
        "    def get_netcdf_result(self):\n",
        "        \n",
        "        time = self.poem.sel(time=slice(self.test_start, self.test_end)).time\n",
        "\n",
        "        if self.projection:\n",
        "            time = xr.open_dataset(self.projection_path).time\n",
        "\n",
        "        if self.max_num_inference_steps is not None:\n",
        "            time = time.isel(time=slice(0, (self.max_num_inference_steps+1)*self.tst_batch_sz))\n",
        "\n",
        "        latitude = self.poem.latitude\n",
        "        longitude = self.poem.longitude\n",
        "        \n",
        "        gan_data= xr.DataArray(\n",
        "            data=self.model_output,\n",
        "            dims=[\"time\", \"latitude\", \"longitude\"],\n",
        "            coords=dict(\n",
        "                time=time,\n",
        "                latitude=latitude,\n",
        "                longitude=longitude,\n",
        "            ),\n",
        "            attrs=dict(\n",
        "                description=\"gan_precipitation\",\n",
        "                units=\"mm/s\",\n",
        "            ))\n",
        "        \n",
        "        gan_dataset = gan_data.to_dataset(name=\"gan_precipitation\")\n",
        "        self.gan_dataset = gan_dataset.transpose('time', 'latitude', 'longitude')\n",
        "\n",
        "        return self.gan_dataset\n",
        "\n",
        "\n",
        "    def inv_transform(self, data, reference=None):\n",
        "        \"\"\" The output equals ERA5, therefore it needs to be\n",
        "            constraind with respect to it\n",
        "        \"\"\"\n",
        "        if reference is None:\n",
        "            reference = self.era5.era5_precipitation.sel(time=slice(self.train_start, self.train_end)).values\n",
        "\n",
        "        if 'log' in self.transforms:\n",
        "            reference = log_transform(reference, self.epsilon)\n",
        "\n",
        "        if 'normalize' in self.transforms:\n",
        "            data = inv_norm_transform(data, reference)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in self.transforms:\n",
        "            data = inv_norm_minus1_to_plus1_transform(data, reference)\n",
        "\n",
        "        if 'log' in self.transforms:\n",
        "            data = inv_log_transform(data, self.epsilon)\n",
        "\n",
        "        return data\n",
        "\n",
        "    \n",
        "    def write(self, fname):\n",
        "        \n",
        "        ds = self.get_netcdf_result()\n",
        "        path  = self.results_path + fname\n",
        "        #path  ='/content/gdrive/MyDrive/bias_gan/results/' + fname\n",
        "        ds.to_netcdf(path)\n"
      ],
      "metadata": {
        "id": "JSAIRPD4--Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluate checkpoints fct"
      ],
      "metadata": {
        "id": "bgA1wp1y-yxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folder(path):\n",
        "    from pathlib import Path\n",
        "    Path(path).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "uhJrYeojF8s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluateCheckpoints():\n",
        "    \"\"\" \n",
        "        Interate over model checkpoints and\n",
        "        show the test set results.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 checkpoint_path,\n",
        "                 config_path,\n",
        "                 plot_summary=False,\n",
        "                 show_plots=False,\n",
        "                 save_model=True,\n",
        "                 constrain=False,\n",
        "                 epoch_index=None,\n",
        "                 projection=False,\n",
        "                 max_num_inference_steps=None,\n",
        "                 projection_path=None\n",
        "                 ):\n",
        "\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        print(f'loading checkpoints from directory: {self.checkpoint_path}')\n",
        "        #self.config_path = \"/data/checkpoint_folder/config_model_f9ffc4a0-7ae1-11ed-b373-fd94a6d70968.json\" #Config.config_path #'/results/'#Config.config_path\n",
        "        self.config_path = config_path\n",
        "        self.reports_path = f'{Config.results_path}reports/'\n",
        "        self.projection_path = projection_path\n",
        "        self.projection = projection\n",
        "        self.plot_summary = plot_summary\n",
        "        self.uuid = None\n",
        "        self.show_plots = show_plots\n",
        "        self.gan_results = None\n",
        "        self.save_model = save_model\n",
        "        self.model_fname = 'gan.nc'\n",
        "        self.model = None\n",
        "        self.test_data = None\n",
        "        self.constrain = constrain\n",
        "        self.epoch_index = epoch_index\n",
        "        self.max_num_inference_steps = max_num_inference_steps\n",
        "\n",
        "\n",
        "    def load_config(self):\n",
        "        path = self.config_path\n",
        "            #print(\"path print\",config_from_file)\n",
        "        #self.uuid = self.get_uuid_from_path(path)\n",
        "            #print(\"self.uuid print\",self.uuid)\n",
        "        #config = config_from_file(f'{self.config_path}config_model_{self.uuid}.json')\n",
        "        config = config_from_file(path)\n",
        "            #print(\"config print\",print)\n",
        "        if self.projection_path is not None:\n",
        "            config.projection_path = self.projection_path\n",
        "        return config\n",
        "\n",
        "\n",
        "\n",
        "    def get_uuid_from_path(self, path: str):\n",
        "        import re\n",
        "        print(\"path in get_uuid\", path)\n",
        "        uuid4hex = re.compile('[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}', re.I)\n",
        "        print(\"uuid4hex\",uuid4hex)\n",
        "        print(\"uuid4hex search path\",uuid4hex.search(path))\n",
        "        uuid = uuid4hex.search(path).group(0)\n",
        "        return uuid\n",
        "\n",
        "\n",
        "    def run(self):         ############## maybe add checkpoint_path as variable ##############\n",
        "        \n",
        "        self.config = self.load_config()\n",
        "        #files = self.get_files(self.checkpoint_path)\n",
        "        #if self.epoch_index is not None:\n",
        "        #    files = [files[self.epoch_index-1]]\n",
        "        \n",
        "        files = [self.checkpoint_path]\n",
        "        for i, fname in enumerate(files):\n",
        "            self.checkpoint_idx = i+1\n",
        "            self.num_checkpoints = len(files)\n",
        "            print(f'Checkpoint {self.checkpoint_idx} / {self.num_checkpoints}:')\n",
        "            print(fname)\n",
        "            print('')\n",
        "            self.run_inference(fname)\n",
        "            self.read_test_data()\n",
        "            self.get_plots()\n",
        "            \n",
        "        return self.get_test_data()\n",
        "        \n",
        "        \n",
        "    def get_files(self, path: str):\n",
        "        \n",
        "        if os.path.isfile(path):\n",
        "            files = []\n",
        "            files.append(path) \n",
        "        else:\n",
        "            files = os.listdir(path)\n",
        "            for i, f in enumerate(files):\n",
        "                files[i] = os.path.join(path, f) \n",
        "        return files\n",
        "\n",
        "    def run_inference(self, path: str):\n",
        "        \n",
        "        inf = Inference(self.config,\n",
        "                        constrain=self.constrain,\n",
        "                        projection=self.projection,\n",
        "                        projection_path=self.projection_path,\n",
        "                        max_num_inference_steps=self.max_num_inference_steps)\n",
        "        inf.load_model(path)\n",
        "        inf.compute()\n",
        "        self.gan_results = inf.get_netcdf_result()\n",
        "        self.model = inf.get_model()\n",
        "        \n",
        "        #if self.save_model:\n",
        "            #self.gan_results.to_netcdf('/content/gdrive/MyDrive/bias_gan/results/' + self.model_fname)\n",
        "        if self.save_model:\n",
        "            inf.write(self.model_fname)\n",
        "    \n",
        "        \n",
        "    def read_test_data(self):\n",
        "    \n",
        "        climate_model = xr.open_dataset(self.config.poem_path)\n",
        "        if 'poem_precipitation' in climate_model.variables:\n",
        "            climate_model =  climate_model.poem_precipitation\n",
        "        else:\n",
        "            climate_model =  climate_model.precipitation\n",
        "        era5 = xr.open_dataset(self.config.era5_path).era5_precipitation\n",
        "        gan = self.gan_results.gan_precipitation\n",
        "\n",
        "        data = TestData(era5, gan, climate_model=climate_model)\n",
        "        data.convert_units()\n",
        "        data.crop_test_period()\n",
        "        data.show_mean()\n",
        "        data.uuid = self.uuid\n",
        "        data.model = self.model\n",
        "        \n",
        "        self.test_data = data\n",
        "\n",
        "\n",
        "    def get_test_data(self):\n",
        "        return self.test_data\n",
        "\n",
        "\n",
        "    def show_reports(self, uuid):\n",
        "        path = f'{self.reports_path}{uuid}/'\n",
        "        files = self.get_files(path)\n",
        "        for file in files:\n",
        "            fig = Image(filename=file)\n",
        "            display(fig)\n",
        "        \n",
        "        \n",
        "    def get_plots(self):\n",
        "\n",
        "        if self.plot_summary:\n",
        "            plot = PlotAnalysis(self.test_data)\n",
        "            new_dir = f'{self.reports_path}{self.uuid}/'\n",
        "            create_folder(new_dir)\n",
        "            fname = f'{new_dir}model_{self.uuid}_number_{self.checkpoint_idx}.png'\n",
        "            plot.summary(plot_idx=self.checkpoint_idx, \n",
        "                         num_plots=self.num_checkpoints,\n",
        "                         fname=fname, show_plots=self.show_plots)"
      ],
      "metadata": {
        "id": "CvdLnaDF-0lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "2adJLjPo-15I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## eval imports"
      ],
      "metadata": {
        "id": "ecz59xDYFx7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline\n",
        "from Bias_GAN.code.src.utils import show_checkpoints\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "import torch\n",
        "#from tqdm import tqdm\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from Bias_GAN.code.src.model import  DataModule, ConstrainedGenerator\n",
        "from Bias_GAN.code.src.data import TestData, CycleDataset, ProjectionDataset,  load_cmip6_model, CMIP6Data\n",
        "from Bias_GAN.code.src.plots import PlotAnalysis\n",
        "from Bias_GAN.code.src.utils import log_transform, inv_norm_transform, inv_log_transform, inv_norm_minus1_to_plus1_transform, norm_minus1_to_plus1_transform, config_from_file\n",
        "#from Bias_GAN.code.main import Config\n",
        "#from Bias_GAN.code.src.quantile_mapping import QuantileMapping\n",
        "from Bias_GAN.code.src.projection_utils import ProjectionPreparation\n",
        "from Bias_GAN.code.src.xarray_utils import write_dataset"
      ],
      "metadata": {
        "id": "pj4vNt8OPi8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define plot functions"
      ],
      "metadata": {
        "id": "cUzMub7XI6cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.ticker\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "class PlotAnalysis():\n",
        "    \n",
        "    def __init__(self, data: TestData):\n",
        "        \n",
        "        self.data = data\n",
        "\n",
        "        #self.names = ['era5', 'poem', 'gan']\n",
        "        self.names = ['era5', 'gan', 'poem']\n",
        "                 #self.names = ['era5', 'poem', 'cmip_model',   \\\n",
        "                 #'quantile_mapping', 'gan_constrained']\n",
        "\n",
        "    def single_frames(self, vmin=0,\n",
        "                              vmax=20,\n",
        "                              time_index=-1,\n",
        "                              cmap='Blues',\n",
        "                              mask=False,\n",
        "                              single_plot=False,\n",
        "                              projection=\"robin\"):\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(12,7),  constrained_layout=True)\n",
        "        alpha = 1.0 \n",
        "        name = ['era5','gan', 'climate_model']\n",
        "        letters = ['a', 'b', 'c']\n",
        "\n",
        "        for ax, (name, letter) in zip(axs, zip(name, letters)):\n",
        "            data = abs(getattr(self.data, name).isel(time=time_index))\n",
        "            if name == 'era5':\n",
        "                print(data.time.values)\n",
        "\n",
        "            ax.annotate(f\"{letter}\", ha=\"center\", va=\"center\", size=15,\n",
        "                        xy=(1-0.955, 0.925), xycoords=ax,\n",
        "                        bbox=None) \n",
        "            ax.set_title(self.data.model_name_definition(name))\n",
        "            plt.title(self.data.model_name_definition(name))\n",
        "\n",
        "            cbar = False\n",
        "            cbar_title = ''\n",
        "\n",
        "            cs = plot_basemap(data, cbar_title, vmin, vmax, alpha, cmap,\n",
        "                        cbar=cbar,\n",
        "                        axis=ax,\n",
        "                        return_cs=True,\n",
        "                        projection=projection,\n",
        "                        map_resolution='c',\n",
        "                        plot_mask=mask)\n",
        "                 \n",
        "        norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
        "        sm = plt.cm.ScalarMappable(norm=norm, cmap = cmap)\n",
        "        sm.set_array([])\n",
        "\n",
        "        cbar = fig.colorbar(sm,\n",
        "                     ax=axs,\n",
        "                     location='bottom',\n",
        "                     shrink=0.4,\n",
        "                     aspect=10,\n",
        "                     extend='max'\n",
        "                     ).set_label('Precipitation [mm/d]', fontsize=13)\n",
        "\n",
        "def plot_basemap(data: xr.DataArray,\n",
        "                cbar_title: str,\n",
        "                vmin: float,\n",
        "                vmax: float,\n",
        "                alpha: float,\n",
        "                cmap: str,\n",
        "                cbar=True,\n",
        "                cbar_extend='max',\n",
        "                cbar_position='right',\n",
        "                return_cs=False,\n",
        "                axis=None,\n",
        "                plot_mask=False,\n",
        "                draw_coordinates=False,\n",
        "                parallel_label=[1, 0, 0, 0],\n",
        "                meridian_label=[0, 0, 0, 1],\n",
        "                contours=None,\n",
        "                fig=None,\n",
        "                projection='mill',\n",
        "                contourf=False,\n",
        "                map_resolution='l',\n",
        "                vmin_contours=0.15,\n",
        "                vmax_contours=0.40,\n",
        "                mask_threshold=1):\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    if axis is not None:\n",
        "        cbar_plt = plt\n",
        "        plt = axis\n",
        "\n",
        "    lats = data.latitude\n",
        "    lons = data.longitude\n",
        "\n",
        "    if projection == 'mill':\n",
        "        lon_0 = 0\n",
        "    else:\n",
        "        lon_0 = -180 \n",
        "\n",
        "    m = Basemap(llcrnrlon=lons[0], llcrnrlat=lats[0],\n",
        "                urcrnrlon=lons[-1], urcrnrlat=lats[-1],\n",
        "                projection=projection, lon_0=lon_0, \n",
        "                resolution=map_resolution, ax=axis)\n",
        "\n",
        "    m.drawcoastlines(color='k', linewidth=0.5)\n",
        "                    \n",
        "    if draw_coordinates:\n",
        "        par = m.drawparallels(\n",
        "                              [-90, -60, 0, 60, 90],\n",
        "                              #[-90, -45, 0, 45, 90],\n",
        "                              linewidth=1.0,\n",
        "                              labels=parallel_label,\n",
        "                              color='grey')\n",
        "\n",
        "        merid = m.drawmeridians(\n",
        "                                [ -90, 0, 90, 180],\n",
        "                                #[-120, -60, 0, 60, 120, 180],\n",
        "                                linewidth=1.0,\n",
        "                                labels=meridian_label,\n",
        "                                color='grey')\n",
        "    \n",
        "    Lon, Lat = np.meshgrid(lons, lats)\n",
        "    \n",
        "    x, y = m(Lon, Lat)\n",
        "                    \n",
        "    if contourf:\n",
        "        cs = plt.contourf(x, y, data, 500, vmin=vmin, vmax=vmax,\n",
        "                        alpha=alpha, cmap=cmap,\n",
        "                        linewidth=0, shading='auto', extend='max')\n",
        "    else:\n",
        "        cs = plt.pcolormesh(x, y, data, vmin=vmin, vmax=vmax,\n",
        "                        alpha=alpha, cmap=cmap,\n",
        "                        linewidth=0, shading='auto')\n",
        "\n",
        "    if plot_mask is True:\n",
        "        mask = np.ma.masked_where(data > mask_threshold, data)\n",
        "        plt.pcolormesh(x,y, mask, vmin=-1, vmax=-1, alpha=1.0, cmap='Greys',shading='auto')\n",
        "\n",
        "    if contours is not None:\n",
        "        cs2 = plt.contour(x, y, abs(contours), 8, \n",
        "                            alpha=1.0, cmap='YlOrRd',\n",
        "                            linewidth=4.0, shading='auto')\n",
        "    if axis is None:\n",
        "        ax = plt.gca()\n",
        "        divider = make_axes_locatable(ax)\n",
        "        cax = divider.append_axes(cbar_position, size=\"1.5%\", pad=0.4)\n",
        "        cbar_plt = cax\n",
        "    if cbar:\n",
        "\n",
        "        if axis is not None:\n",
        "            ax = cbar_plt.gca()\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes(cbar_position, size=\"2.5%\", pad=0.2)\n",
        "            cbar = cbar_plt.colorbar(cs, cax=cax,  label=cbar_title, extend=cbar_extend)\n",
        "        else:\n",
        "            cbar = plt.colorbar(cs, cax=cax,  label=cbar_title, extend=cbar_extend)\n",
        "\n",
        "        cbar.solids.set(alpha=1)\n",
        "        if cbar_position == 'left':\n",
        "            cbar.ax.yaxis.set_ticks_position('left')\n",
        "            cbar.ax.yaxis.set_label_position('left')\n",
        "\n",
        "        if contours is not None:\n",
        "            norm = matplotlib.colors.Normalize(vmin=cs2.cvalues.min(), vmax=cs2.cvalues.max())\n",
        "            sm = plt.cm.ScalarMappable(norm=norm, cmap = cs2.cmap)\n",
        "            sm.set_array([])\n",
        "\n",
        "            #cax = divider.new_vertical(size=\"3%\", pad=0.2, pack_start=True)\n",
        "            cax = divider.append_axes('right', size=\"1.5%\", pad=0.2)\n",
        "            #fig.add_axes(cax)\n",
        "            fig.colorbar(sm,\n",
        "                         ticks=cs2.levels,\n",
        "                         cax=cax,\n",
        "                         #orientation=\"horizontal\",\n",
        "                         orientation=\"vertical\",\n",
        "                         extend='max',\n",
        "                         label='Feature importance [a.u.]')\n",
        "\n",
        "    else:\n",
        "        #cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
        "        if axis is None:\n",
        "            cax.set_visible(False)\n",
        "    if return_cs:\n",
        "        return cs"
      ],
      "metadata": {
        "id": "PcHg7xqCI9dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Evaluation\n"
      ],
      "metadata": {
        "id": "VGpAmsXwFzjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/gdrive/MyDrive/bias_gan/results/2023_01_09_07h_46m_22s/last.ckpt\" \n",
        "config_path = \"/content/gdrive/MyDrive/bias_gan/results/2023_01_09_07h_46m_22s/config_model.json\"\n",
        "\n",
        "data = EvaluateCheckpoints(checkpoint_path=checkpoint_path, config_path=config_path, save_model=True)"
      ],
      "metadata": {
        "id": "LeBFJMy3-NSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.run()"
      ],
      "metadata": {
        "id": "m3QONUVL_OMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data.get_test_data()"
      ],
      "metadata": {
        "id": "QZnmmO0oHfte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot single frames"
      ],
      "metadata": {
        "id": "rOMdYqIrEBEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_index=10\n",
        "\n",
        "PlotAnalysis(test_data).single_frames(time_index=time_index)\n",
        "PlotAnalysis(test_data).single_frames(projection=\"cyl\",time_index=time_index)"
      ],
      "metadata": {
        "id": "UdNmJG-jHyGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot PSD"
      ],
      "metadata": {
        "id": "lXihevAlFamY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy==1.21.2 \n",
        "!pip install pysteps #pysteps==1.3.2\n"
      ],
      "metadata": {
        "id": "ng1bUtOqGGga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pysteps.utils.spectral import rapsd, corrcoef\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "\n",
        "class SpatialSpectralDensity():\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        self.time_period = ('2001', '2014')\n",
        "        self.num_times = None\n",
        "        \n",
        "        fname = '/data/gan.nc'\n",
        "        self.gan = xr.open_dataset('/content/gdrive/MyDrive/bias_gan/results/gan.nc').gan_precipitation \n",
        "        \n",
        "        self.era5 = xr.open_dataset(Config.era5_path).era5_precipitation*3600*24 \n",
        "        self.poem = xr.open_dataset(Config.poem_path).precipitation*3600*24 \n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "    def compute_mean_spectral_density(self, data: xr.DataArray):\n",
        "        \n",
        "        #data = data.sel(time=slice(self.time_period[0], self.time_period[1]))\n",
        "        data = data.isel(longitude=slice(0+10,59+10), latitude=slice(0+10,59+10))\n",
        "        num_frequencies = np.max((len(data.latitude.values),\n",
        "                                  len(data.longitude.values)))/2\n",
        "        mean_spectral_density = np.zeros(int(num_frequencies))\n",
        "        if self.num_times is None:\n",
        "            num_times = int(len(data.time))\n",
        "            \n",
        "        elif self.timestamp is not None:\n",
        "            num_times = 1\n",
        "            \n",
        "        else:\n",
        "            num_times = self.num_times\n",
        "        \n",
        "        for t in range(num_times):\n",
        "            if self.timestamp is not None:\n",
        "                tmp = data.sel(time=self.timestamp).values\n",
        "            else:\n",
        "                tmp = data.isel(time=t).values\n",
        "            psd, freq = rapsd(tmp, return_freq=True, normalize=True, fft_method=np.fft)\n",
        "            mean_spectral_density += psd\n",
        "        mean_spectral_density /= num_times\n",
        "        \n",
        "        return mean_spectral_density, freq\n",
        "    \n",
        "    \n",
        "    def run(self, num_times=None, timestamp=None):\n",
        "        \n",
        "        self.num_times = num_times\n",
        "        self.timestamp = timestamp\n",
        "        self.gan_psd, self.freq = self.compute_mean_spectral_density(self.gan)\n",
        "        self.era5_psd, self.freq = self.compute_mean_spectral_density(self.era5)\n",
        "        self.poem_psd, self.freq = self.compute_mean_spectral_density(self.poem)\n",
        "        #self.cmip_psd, self.freq = self.compute_mean_spectral_density(self.cmip)\n",
        "        #self.quantile_mapping_psd, self.freq = self.compute_mean_spectral_density(self.quantile_mapping)\n",
        "        \n",
        "        \n",
        "    def plot(self, axis=None, fname=None, fontsize=None, linewidth=None):\n",
        "        \n",
        "\n",
        "        if axis is None: \n",
        "            _, ax = plt.subplots(figsize=(7,6))\n",
        "        else:\n",
        "            ax = axis\n",
        "\n",
        "        plt.rcParams.update({'font.size': 12})\n",
        "        x_vals = 1/self.freq*3.75*111/2\n",
        "        ax.plot(x_vals, self.era5_psd, label='ERA5', color='k', linewidth=linewidth)\n",
        "        ax.plot(x_vals, self.poem_psd, label='CM2Mc-LPJmL', color='r', linewidth=linewidth)\n",
        "        #ax.plot(x_vals, self.cmip_psd, label='GFDL-ESM4', color='b', linewidth=linewidth)\n",
        "        #ax.plot(x_vals, self.quantile_mapping_psd, label='Quantile mapping', color='m', linewidth=linewidth)\n",
        "        ax.plot(x_vals, self.gan_psd, label='GAN', color='c', linewidth=linewidth)\n",
        "        ax.legend(loc='lower left', fontsize=fontsize)\n",
        "        ax.set_xlim(x_vals[1]+1024, x_vals[-1]-32)\n",
        "        ax.set_yscale('log', basey=2)\n",
        "        ax.set_xscale('log', basex=2)\n",
        "        ax.set_xticks([2**9, 2**10, 2**11, 2**12, 2**13])\n",
        "        ax.tick_params(axis='x', labelsize=fontsize)\n",
        "        ax.tick_params(axis='y', labelsize=fontsize)\n",
        "        ax.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\n",
        "        ax.grid()\n",
        "        ax.set_ylim(4.5e-5, 0.07)\n",
        "        ax.set_xlabel(r'k [km]', fontsize=fontsize)\n",
        "        ax.set_ylabel('PSD [a.u]', fontsize=fontsize)\n",
        "        \n",
        "        if fname is not None:\n",
        "            plt.savefig(fname, format='pdf', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "vrBG-HX2F1yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from Bias_GAN.code.src.spectral_density import SpatialSpectralDensity\n",
        "ssd = SpatialSpectralDensity()\n",
        "ssd.run(num_times=None)\n",
        "\n",
        "\n",
        "fname = f'/results/poem_gan_psd.pdf' \n",
        "ssd.plot(fname=fname)\n",
        "print(fname)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "plot = PlotAnalysis(plot_data)\n",
        "\n",
        "fname = f'/results/poem_gan_single_frame.pdf' \n",
        "\n",
        "plot.single_frames(cmap='YlGnBu', time_index=-7, mask=True)\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "plt.savefig(fname, format='pdf', bbox_inches='tight')\n",
        "plt.show()\n",
        "print(fname)\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "5rANAaPECAma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kqc95UtkFjwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}